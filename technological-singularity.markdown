[][1]

# Technological singularity

From Wikipedia, the free encyclopedia

Jump to: [navigation][2], [search][3]

The **technological singularity** is the hypothetical future emergence of [greater-than-human 
intelligence][4] through technological means.[[1]][5] Since the capabilities 
of such intelligence would be difficult for an unaided human mind to comprehend, 
the occurrence of a technological singularity is seen as an intellectual [event 
horizon][6], beyond which events cannot be predicted or understood. Proponents 
of the singularity typically state that an "intelligence explosion"[[2]][7][[3]][8] 
is a key factor of the Singularity where superintelligences design successive 
generations of increasingly powerful minds.

This hypothesized process of intelligent self-modification might occur very 
quickly, and might not stop until the agent's cognitive abilities greatly surpass 
that of any human. The term "intelligence explosion" is therefore sometimes 
used to refer to this scenario.[[2]][7]

The term was coined by science fiction writer [Vernor Vinge][9], who argues 
that artificial intelligence, human biological enhancement or brain-computer 
interfaces could be possible causes of the singularity. The concept is popularized 
by futurists like [Ray Kurzweil][10] and it is expected by proponents to occur 
sometime in the 21st century, although estimates vary.

|

## Contents

* [1 Basic concepts][11]
* [2 History of the idea][12]
* 
[3 Intelligence explosion][13]

* [3.1 Speed improvements][14]
* [3.2 Intelligence improvements][15]
* 
[3.3 Impact][16]

* [3.3.1 Existential risk][17]

* [3.4 Implications for human society][18]

* [4 Accelerating change][19]
* 
[5 Criticism][20]

* [5.1 Criticism of the accelerating returns argument][21]

* [6 In popular culture][22]
* [7 See also][23]
* [8 Notes][24]
* [9 References][25]
* 
[10 External links][26]

* [10.1 Essays and articles][27]
* [10.2 Singularity AI projects][28]
* [10.3 Fiction][29]
* [10.4 Other links][30]

|

##  [[edit][31]] Basic concepts 

[![][32]][33]

[![][34]][33]
[Kurzweil][10] writes that, due to [paradigm shifts][35], a trend of exponential growth extends [Moore's law][36] from [integrated circuits][37] to earlier [transistors][38], [vacuum tubes][39], [relays][40], and [electromechanical][41] computers. He predicts that the exponential growth will continue, and that in a few decades the computing power of all computers will exceed that of human brains, with superhuman [artificial intelligence][42] appearing around the same time.

Many of the most recognized writers on the singularity, such as [Vernor Vinge][9] 
and [Ray Kurzweil][10], define the concept in terms of the technological creation 
of [superintelligence][4], and argue that it is difficult or impossible for 
present-day humans to predict what a post-singularity world would be like, 
due to the difficulty of imagining the intentions and capabilities of superintelligent 
entities.[[4]][43][[5]][44][[6]][45] The term "technological singularity" was 
originally coined by Vinge, who made an analogy between the breakdown in our 
ability to predict what would happen after the development of superintelligence 
and the breakdown of the predictive ability of modern [physics][46] at the 
[space-time singularity][47] beyond the [event horizon][6] of a [black hole][48].[[6]][45] 
Some writers use "the singularity" in a broader way to refer to any radical 
changes in our society brought about by new technologies such as [molecular 
nanotechnology][49],[[7]][50][[8]][51][[9]][52] although Vinge and other prominent 
writers specifically state that without superintelligence, such changes would 
not qualify as a true singularity.[[4]][43] Many writers also tie the singularity 
to observations of exponential growth in various technologies (with [Moore's 
Law][53] being the most prominent example), using such observations as a basis 
for predicting that the singularity is likely to happen sometime within the 
21st century.[[8]][51][[10]][54]

A technological singularity includes the concept of an intelligence explosion, 
a term coined in 1965 by [I. J. Good][55].[[11]][56] Although technological 
progress has been accelerating, it has been limited by the basic intelligence 
of the human brain, which has not, according to [Paul R. Ehrlich][57], changed 
significantly for millennia.[[12]][58] However with the increasing power of 
computers and other technologies, it might eventually be possible to build 
a machine that is more intelligent than humanity.[[13]][59] If superhuman intelligences 
were invented, either through the [amplification of human intelligence][60] 
or [artificial intelligence][42], it would bring to bear greater problem-solving 
and inventive skills than humans, then it could design a yet more capable machine, 
or re-write its source code to become more intelligent. This more capable machine 
could then go on to design a machine of even greater capability. These iterations 
could accelerate, leading to [recursive self improvement][61], potentially 
allowing enormous qualitative change before any upper limits imposed by the 
laws of physics or theoretical computation set in.[[14]][62][[15]][63][[16]][64] 

The exponential growth in computing technology suggested by Moore's Law is 
commonly cited as a reason to expect a singularity in the relatively near future, 
and a number of authors have proposed generalizations of Moore's Law. Computer 
scientist and futurist [Hans Moravec][65] proposed in a 1998 book that the 
exponential growth curve could be extended back through earlier computing technologies 
prior to the [integrated circuit][66]. Futurist Ray Kurzweil postulates a [law 
of accelerating returns][67] in which the speed of technological change (and 
more generally, all evolutionary processes[[17]][68]) increases exponentially, 
generalizing Moore's Law in the same manner as Moravec's proposal, and also 
including material technology (especially as applied to [nanotechnology][69]), 
medical technology and others.[[18]][70] Like other authors, though, he reserves 
the term "Singularity" for a rapid increase in _intelligence_ (as opposed to 
other technologies), writing for example that "The Singularity will allow us 
to transcend these limitations of our biological bodies and brains ... There 
will be no distinction, post-Singularity, between human and machine".[[19]][71] 
He also defines his predicted date of the singularity (2045) in terms of when 
he expects computer-based intelligences to significantly exceed the sum total 
of human brainpower, writing that advances in computing before that date "will 
not represent the Singularity" because they do "not yet correspond to a profound 
expansion of our intelligence."[[20]][72]

The term "technological singularity" reflects the idea that such change may 
happen suddenly, and that it is difficult to predict how such a new world would 
operate.[[21]][73][[22]][74] It is unclear whether an intelligence explosion 
of this kind would be beneficial or harmful, or even an [existential threat][75],[[23]][76][[24]][77] 
as the issue has not been dealt with by most [artificial general intelligence][78] 
researchers, although the topic of [friendly artificial intelligence][79] is 
investigated by the [Singularity Institute for Artificial Intelligence][80] 
and the [Future of Humanity Institute][81].[[21]][73]

Many prominent technologists and academics dispute the plausibility of a technological 
singularity, including [Jeff Hawkins][82], [John Holland][83], [Jaron Lanier][84], 
and [Gordon Moore][85], whose Moore's Law is often cited in support of the 
concept.[[25]][86][[26]][87]

##  [[edit][88]] History of the idea 

In the middle of the 19th century in one of his works [Friedrich Engels][89] 
wrote that science moves forward proportionally to the "mass of knowledge" 
inherited from the previous generations, he proposed a more formal mathematical 
concept that since the 16th century the development of the sciences had been 
increasing proportionally to the squared distance in time from its start.

In 1847, R. Thornton, the editor of the Primitive Expounder,[[27]][90] wrote 
(more than half in jest) about the recent invention of a four function [mechanical 
calculator][91]:

>  ...such machines, by which the scholar may, by turning a crank, grind out 
> the solution of a problem without the fatigue of mental application, would 
> by its introduction into schools, do incalculable injury. But who knows that 
> such machines when brought to greater perfection, may not think of a plan to 
> remedy all their own defects and then grind out ideas beyond the ken of mortal 
> mind! 

In 1951 [Alan Turing][92] spoke of machines outstripping humans intellectually:[[28]][93] 

>  once the machine thinking method has started, it would not take long to outstrip 
> our feeble powers. ... At some stage therefore we should have to expect the 
> machines to take control, in the way that is mentioned in [Samuel Butler][94]'s 
> '[Erewhon][95]'. 

In 1958, [Stanisław Ulam][96] wrote in reference[[29]][97] to a conversation 
with [John von Neumann][98]:

>  One conversation centered on the ever accelerating progress of technology 
> and changes in the mode of human life, which gives the appearance of approaching 
> some essential singularity in the history of the race beyond which human affairs, 
> as we know them, could not continue. 

In 1965, [I. J. Good][55] first wrote of an "intelligence explosion", suggesting 
that if machines could even slightly surpass human intellect, they could improve 
their own designs in ways unforeseen by their designers, and thus [recursively][99] 
augment themselves into far greater intelligences. The first such improvements 
might be small, but as the machine became more intelligent it would become 
better at becoming more intelligent, which could lead to a cascade of self-improvements 
and a sudden surge to [superintelligence][4] (or a singularity).

In 1983 mathematician and author [Vernor Vinge][9] greatly popularized Good’s 
notion of an intelligence explosion in a number of writings, first addressing 
the topic in print in the January 1983 issue of _[Omni][100]_ magazine. In 
this op-ed piece, Vinge seems to have been the first to use the term "singularity" 
in a way that was specifically tied to the creation of intelligent machines,[[30]][101][[31]][102] 
writing:

>  We will soon create intelligences greater than our own. When this happens, 
> human history will have reached a kind of singularity, an intellectual transition 
> as impenetrable as the knotted space-time at the center of a black hole, and 
> the world will pass far beyond our understanding. This singularity, I believe, 
> already haunts a number of science-fiction writers. It makes realistic extrapolation 
> to an interstellar future impossible. To write a story set more than a century 
> hence, one needs a nuclear war in between ... so that the world remains intelligible. 
>  

In 1984 [Samuel R. Delany][103] used "cultural fugue" as a plot device in his 
science fiction novel _[Stars in My Pocket Like Grains of Sand][104]_; the 
terminal runaway of technological and cultural complexity in effect destroys 
all life on any world on which it transpires, a process which is poorly understood 
by the novel's characters, and against which they seek a stable defense. In 
1985 [Ray Solomonoff][105] introduced the notion of "infinity point"[[32]][106] 
in the time scale of artificial intelligence, analyzed the magnitude of the 
"[future shock][107]" that "we can expect from our AI expanded scientific community" 
and on social effects. Estimates were made "for when these milestones would 
occur, followed by some suggestions for the more effective utilization of the 
extremely rapid technological growth that is expected."

Vinge also popularized the concept in SF novels such as _[Marooned in Realtime][108]_ 
(1986) and _[A Fire Upon the Deep][109]_ (1992). The former is set in a world 
of rapidly [accelerating change][110] leading to the emergence of more and 
more sophisticated technologies separated by shorter and shorter time intervals, 
until a point beyond human comprehension is reached. The latter starts with 
an imaginative description of the evolution of a [superintelligence][4] passing 
through exponentially accelerating developmental stages ending in a [transcendent][111], 
almost [omnipotent][112] power unfathomable by mere humans. It is also implied 
that the development does not stop at this level.

In his 1988 book _Mind Children_, computer scientist and futurist [Hans Moravec][65] 
generalizes Moore's law to make predictions about the future of artificial 
life. Moravec outlines a timeline and a scenario in this regard,[[33]][113][[34]][114] 
in that the robots will evolve into a new series of artificial species, starting 
around 2030-2040.[[35]][115] In _Robot: Mere Machine to Transcendent Mind_, 
published in 1998, Moravec further considers the implications of evolving [robot 
intelligence][116], generalizing Moore's law to technologies predating the 
[integrated circuit][66], and speculating about a coming "mind fire" of rapidly 
expanding [superintelligence][4], similar to Vinge's ideas.

A 1993 article by Vinge, "The Coming Technological Singularity: How to Survive 
in the Post-Human Era",[[4]][43] was widely disseminated on the internet and 
helped to popularize the idea.[[36]][117] This article contains the oft-quoted 
statement, "Within thirty years, we will have the technological means to create 
superhuman intelligence. Shortly after, the human era will be ended." Vinge 
refines his estimate of the time scales involved, adding, "I'll be surprised 
if this event occurs before 2005 or after 2030."

Vinge predicted four ways the Singularity could occur:

1. The development of computers that are "awake" and superhumanly intelligent. 

2. Large computer networks (and their associated users) may "wake up" as a 
superhumanly intelligent entity.

3. Computer/human interfaces may become so intimate that users may reasonably 
be considered superhumanly intelligent.

4. Biological science may find ways to improve upon the natural human intellect.[[37]][118] 

Vinge continues by predicting that superhuman intelligences will be able to 
enhance their own minds faster than their human creators. "When greater-than-human 
intelligence drives progress," Vinge writes, "that progress will be much more 
rapid." This [feedback loop][119] of self-improving intelligence, he predicts, 
will cause large amounts of technological progress within a short period, and 
that the creation of superhuman intelligence represented a breakdown in humans' 
ability to model their future. His argument was that authors cannot write realistic 
characters who surpass the human intellect, as the thoughts of such an intellect 
would be beyond the ability of humans to express. Vinge named this event "the 
Singularity".

[Damien Broderick][120]'s popular science book [The Spike (1997)][121] was 
the first to investigate the technological Singularity in detail. In 2000 [Bill 
Joy][122], a prominent technologist, founder of [Sun Microsystems][123], voiced 
concern over the potential dangers of the Singularity.[[38]][124]

In 2005, Ray Kurzweil published _[The Singularity is Near][125]_, which brought 
the idea of the singularity to the popular media both through the book's accessibility 
and a publicity campaign that included an appearance on _[The Daily Show with 
Jon Stewart][126]_.[[39]][127] The book stirred intense controversy, in part 
because Kurzweil's utopian predictions contrasted starkly with other, darker 
visions of the possibilities of the singularity. Kurzweil, his theories, and 
the controversies surrounding it were the subject of [Barry Ptolemy][128]'s 
documentary _[Transcendent Man][129]_.

In 2007 [Eliezer Yudkowsky][130] suggested[[8]][51] that many of the different 
definitions that have been assigned to _singularity_ are mutually incompatible 
rather than mutually supporting. For example, Kurzweil extrapolates current 
technological trajectories _past_ the arrival of self-improving AI or superhuman 
intelligence, which Yudkowsky argues represents a tension with both I. J. Good's 
proposed discontinuous upswing in intelligence and Vinge's thesis on unpredictability. 
In 2008 [Robin Hanson][131], taking "singularity" to refer to sharp increases 
in the exponent of economic growth, lists the [agricultural][132] and [industrial 
revolutions][133] as past "singularities". Extrapolating from such past events, 
Hanson proposes that the next economic singularity should increase [economic 
growth][134] between 60 and 250 times. An innovation that allowed for the replacement 
of virtually all human labor could trigger this event.[[40]][135]

In 2009, Kurzweil and [X-Prize][136] founder [Peter Diamandis][137] announced 
the establishment of [Singularity University][138], whose stated mission is 
"to assemble, educate and inspire a cadre of leaders who strive to understand 
and facilitate the development of exponentially advancing technologies in order 
to address humanity’s grand challenges."[[41]][139] Funded by [Google][140], 
[Autodesk][141], [ePlanet Ventures][142], and a group of technology industry 
leaders, Singularity University is based at [NASA][143]'s [Ames Research Center][144] 
in [Mountain View][145], [California][146]. The not-for-profit organization 
runs an annual ten-week graduate program during the summer that covers ten 
different technology and allied tracks, and a series of executive programs 
throughout the year. Program faculty include experts in technology, finance, 
and future studies, and a number of videos of Singularity University sessions 
have been posted online.[_[citation needed][147]_]

In 2010 [Aubrey de Grey][148] applied the term the "Methuselarity"[[42]][149] 
to the point at which medical technology improves so fast that [expected human 
lifespan][150] increases by more than one year per year. In 2010 in "Apocalyptic 
AI - Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality,"[[43]][151] 
Robert Geraci offers an account of the developing "cyber-theology" inspired 
by Singularity studies.

In 2011, Kurzweil noted existing trends and concluded that the singularity 
was becoming more probable to occur around 2045. He told _Time_ magazine: "We 
will successfully reverse-engineer the human brain by the mid-2020s. By the 
end of that decade, computers will be capable of human-level intelligence."[[44]][152] 

##  [[edit][153]] Intelligence explosion 

The notion of an "intelligence explosion" is key to the singularity. It was 
first described thus by [Good (1965][154]), who speculated on the effects of 
superhuman machines:

|“|Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.|”|

Most proposed methods for creating superhuman or [transhuman][155] minds fall 
into one of two categories: [intelligence amplification][60] of human brains 
and [artificial intelligence][42]. The means speculated to produce intelligence 
augmentation are numerous, and include [bio-][156] and [genetic engineering][157], 
[nootropic][158] drugs, AI assistants, direct [brain-computer interfaces][159], 
and [mind uploading][160]. The existence of multiple paths to an intelligence-explosion 
makes a singularity more likely; for a singularity to not occur they would 
all have to fail.[[6]][45]

Despite the numerous speculated means for amplifying human intelligence, non-human 
artificial intelligence (specifically [seed AI][61]) is the most popular option 
for organizations trying to advance the singularity. [Hanson (1998][161]) is 
also skeptical of human intelligence augmentation, writing that once one has 
exhausted the "low-hanging fruit" of easy methods for increasing human intelligence, 
further improvements will become increasingly difficult to find.

Whether or not an intelligence explosion occurs depends on three factors.[[45]][162] 
The first, accelerating factor, is the new intelligence enhancements made possible 
by each previous improvement. Contrawise, as the intelligences become more 
advanced, further advances will become more and more complicated, possibly 
overcoming the advantage of increased intelligence. Each improvement must be 
able to beget at least one more improvement, on average, for the singularity 
to continue. Finally, there is the issue of a hard upper limit. Absent [Quantum 
Computing][163], eventually the laws of physics will prevent any further improvements. 

There are two logically independent, but mutually reinforcing, accelerating 
effects: increases in the speed of computation, and improvements to the algorithms 
used.[[46]][164] The former is predicted by [Moore’s Law][165] and the forecast 
improvements in hardware,[[47]][166] and is comparatively similar to previous 
technological advance. On the other hand, most AI researchers believe that 
software is more important than hardware.

###  [[edit][167]] Speed improvements 

The first is the improvements to the speed at which minds can be run. Whether 
human or AI, better hardware increases the rate of future hardware improvements. 
Oversimplified,[[48]][168][Moore's Law][53] suggests that if the first doubling 
of speed took 18 months, the second would take 18 subjective months; or 9 external 
months, whereafter, four months, two months, and so on towards a speed singularity.[[49]][169] 
An upper limit on speed may eventually be reached, though it is unclear how 
high this would be. [Hawkins (2008][170]), responding to Good, argued that 
the upper limit is relatively low;

> 
> Belief in this idea is based on a naive understanding of what intelligence 
> is. As an analogy, imagine we had a computer that could design new computers 
> (chips, systems, and software) faster than itself. Would such a computer lead 
> to infinitely fast computers or even computers that were faster than anything 
> humans could ever build? No. It might accelerate the rate of improvements for 
> a while, but in the end there are limits to how big and fast computers can 
> run. We would end up in the same place; we'd just get there a bit faster. There 
> would be no singularity. Whereas if it were a lot higher than current human 
> levels of intelligence, the effects of the singularity would be enormous enough 
> as to be indistinguishable (to humans) from a singularity with an upper limit. 
> For example, if the speed of thought could be increased a million-fold, a subjective 
> year would pass in 30 physical seconds.[[6]][45]
> 

It is difficult to directly compare [silicon][171]-based hardware with [neurons][172]. 
But [Berglas (2008][173]) notes that computer [speech recognition][174] is 
approaching human capabilities, and that this capability seems to require 0.01% 
of the volume of the brain. This analogy suggests that modern computer hardware 
is within a few orders of magnitude of being as powerful as the human brain. 

###  [[edit][175]] Intelligence improvements 

Some intelligence technologies, like [seed AI][61], may also have the potential 
to make themselves more intelligent, not just faster, by modifying their source 
code. These improvements would make further improvements possible, which would 
make further improvements possible, and so on.

This mechanism for an intelligence explosion differs from an increase in speed 
in two ways. First, it does not require external effect: machines designing 
faster hardware still require humans to create the improved hardware, or to 
program factories appropriately. An AI which was re-writing its own source 
code, however, could do so while contained in an [AI box][176].

Second, as with Vernor Vinge’s conception of the singularity, it is much harder 
to predict the outcome. While speed increases seem to be only a quantitative 
difference from human intelligence, actual improvements in intelligence would 
be qualitatively different. [Eliezer Yudkowsky][130] compares it to the changes 
that human intelligence brought: humans changed the world thousands of times 
more rapidly than evolution had done, and in totally different ways. Similarly, 
the evolution of life had been a massive departure and acceleration from the 
previous geological rates of change, and improved intelligence could cause 
change to be as different again.[[50]][177]

There are substantial dangers associated with an intelligence explosion singularity. 
First, the goal structure of the AI may not be invariant under self-improvement, 
potentially causing the AI to optimise something other than was intended.[[51]][178][[52]][179] 
Secondly, AIs could compete for the scarce resources mankind uses to survive.[[53]][180] 

While not actively malicious, there is no reason to think that AIs would actively 
promote human goals unless they could be programmed as such, and if not, might 
use the resources currently used to support mankind to promote its own goals, 
causing human extinction.[[10]][54][[54]][181][[55]][182]

###  [[edit][183]] Impact 

Dramatic changes in the rate of economic growth have occurred in the past because 
of some technological advancement. Based on population growth, the economy 
doubled every 250,000 years from the [Paleolithic][184] era until the [Neolithic 
Revolution][132]. This new agricultural economy began to double every 900 years, 
a remarkable increase. In the current era, beginning with the [Industrial Revolution][185], 
the world’s economic output doubles every fifteen years, sixty times faster 
than during the agricultural era. If the rise of superhuman intelligences causes 
a similar revolution, argues [Robin Hanson][131], one would expect the economy 
to double at least quarterly and possibly on a weekly basis.[[40]][135]

####  [[edit][186]] Existential risk 

> 
> "The AI does not hate you, nor does it love you, but you are made out of atoms 
> which it can use for something else." ([Eliezer Yudkowsky][130]) [[21]][73] 
> 

Superhuman intelligences may have goals inconsistent with human survival and 
prosperity. [Berglas (2008][173]) notes that there is no direct evolutionary 
motivation for an AI to be friendly to humans. In the same way that evolution 
has no inherent tendency to produce outcomes valued by humans, so too there 
is little reason to expect an arbitrary optimisation process to promote an 
outcome desired by mankind, rather than inadvertently leading to an AI behaving 
in a way not intended by its creators (such as [Nick Bostrom][187]'s whimsical 
example of an AI which was originally programmed with the goal of manufacturing 
paper clips, such that when it achieves superintelligence it decides to convert 
the entire planet into a paper clip manufacturing facility;[[56]][188][[57]][189][[58]][190][Anders 
Sandberg][191] has also elaborated on this scenario, addressing various common 
counter-arguments.[[59]][192]) AI researcher [Hugo de Garis][193] suggests 
that artificial intelligences may simply eliminate the human race for access 
to scarce resources,[[53]][180][[60]][194] and humans would be powerless to 
stop them.[[61]][195]

[Bostrom (2002][196]) discusses human extinction scenarios, and lists [superintelligence][4] 
as a possible cause:

> 
> When we create the first superintelligent entity, we might make a mistake and 
> give it goals that lead it to annihilate humankind, assuming its enormous intellectual 
> advantage gives it the power to do so. For example, we could mistakenly elevate 
> a subgoal to the status of a supergoal. We tell it to solve a mathematical 
> problem, and it complies by turning all the matter in the solar system into 
> a giant calculating device, in the process killing the person who asked the 
> question.
> 

Alternatively, AIs developed under evolutionary pressure to promote their own 
survival could out-compete humanity.[[55]][182] One approach to prevent a negative 
singularity is an [AI box][176], whereby the artificial intelligence is kept 
constrained inside a simulated world and not allowed to affect the external 
world. Such a box would have extremely proscribed inputs and outputs; maybe 
only a plaintext channel. However, a sufficiently intelligent AI may simply 
be able to escape from any box we can create. For example, it might crack the 
[protein folding][197] problem and use nanotechnology to escape, or simply 
persuade its human 'keepers' to let it out.[[21]][73][[62]][198][[63]][199] 

[Eliezer Yudkowsky][130] proposed that research be undertaken to produce [friendly 
artificial intelligence][200] in order to address the dangers. He noted that 
if the first real AI were friendly it would have a head start on self-improvement 
and thus prevent other unfriendly AIs from developing, as well as providing 
enormous benefits to mankind.[[54]][181] The [Singularity Institute for Artificial 
Intelligence][80] is dedicated to this cause.

A significant problem, however, is that unfriendly artificial intelligence 
is likely to be much easier to create than FAI: while both require large advances 
in recursive optimisation process design, friendly AI also requires the ability 
to make goal structures invariant under self-improvement (or the AI will transform 
itself into something unfriendly) and a goal structure that aligns with human 
values and doesn’t automatically destroy the human race. An unfriendly AI, 
on the other hand, can optimize for an arbitrary goal structure, which doesn't 
need to be invariant under self-modification.[[64]][201]

[Bill Hibbard][202] also addresses issues of AI safety and morality in his 
book _[Super-Intelligent Machines][203]_.

###  [[edit][204]] Implications for human society 

In 2009, leading computer scientists, artificial intelligence researchers, 
and roboticists met at the Asilomar Conference Grounds near [Monterey Bay][205] 
in California. The goal was to discuss the potential impact of the hypothetical 
possibility that robots could become self-sufficient and able to make their 
own decisions. They discussed the extent to which computers and robots might 
be able to acquire autonomy, and to what degree they could use such abilities 
to pose threats or hazards. Some machines have acquired various forms of semi-autonomy, 
including the ability to locate their own power sources and choose targets 
to attack with weapons. Also, some [computer viruses][206] can evade elimination 
and have achieved "cockroach intelligence." The conference attendees noted 
that self-awareness as depicted in science-fiction is probably unlikely, but 
that other potential hazards and pitfalls exist.[[65]][207]

Some experts and academics have questioned the use of robots for military combat, 
especially when such robots are given some degree of autonomous functions.[[66]][208] 
A [United States Navy][209] report indicates that, as military robots become 
more complex, there should be greater attention to implications of their ability 
to make autonomous decisions.[[67]][210][[68]][211]

The [Association for the Advancement of Artificial Intelligence][212] has commissioned 
a study to examine this issue,[[69]][213] pointing to programs like the [Language 
Acquisition Device][214], which can emulate human interaction.

Many [Singularitarians][215] consider nanotechnology to be one of the greatest 
dangers facing humanity. For this reason, they often believe that [seed AI][61] 
(an AI capable of making itself smarter) should precede nanotechnology. Others, 
such as the [Foresight Institute][216], advocate the creation of molecular 
nanotechnology, which they claim can be made safe for pre-singularity use or 
expedite the arrival of a beneficial singularity[_[citation needed][147]_]. 

Some support the design of "[friendly artificial intelligence][200]", meaning 
that the advances which are already occurring with AI should also include an 
effort to make AI intrinsically friendly and humane.[[70]][217]

[Isaac Asimov][218]'s [Three Laws of Robotics][219] is one of the earliest 
examples of proposed safety measures for AI:

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey orders given to it by human beings except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with either the First or Second Law.

Additional laws included in some stories were described as follows:

* 
_Zeroth Law:_ A robot may not harm humanity, or through inaction allow humanity to come to harm.
* 
_Minus-One Law:_ A robot may not harm sentience, or through inaction allow sentience to come to harm.
* 
_Fourth Law:_ A robot must establish its identity as a robot in all cases.
* Alternate _Fourth Law:_ A robot must reproduce, unless such reproduction would interfere with the First or Second or Third Law.
* 
_Fifth Law:_ A robot must know it is a robot.

The laws are intended to prevent artificially intelligent robots from harming 
humans. In Asimov’s stories, any perceived problems with the laws tend to arise 
as a result of a misunderstanding on the part of some human operator; the robots 
themselves are merely acting to their best interpretation of their rules. In 
the [2004][220] film _[I, Robot][221]_, loosely based on Asimov's [_Robot_ 
stories][222], an AI attempts to take complete control over humanity for the 
purpose of protecting humanity from itself due to [an extrapolation of the 
Three Laws][223]. In 2004, the Singularity Institute launched an Internet campaign 
called _3 Laws Unsafe_ to raise awareness of AI safety issues and the inadequacy 
of Asimov’s laws in particular. ([Singularity Institute for Artificial Intelligence 
2004][224])

##  [[edit][225]] Accelerating change 

[![][226]][227]

[![][34]][227] According to Kurzweil, his [logarithmic graph][228] of 15 lists of [paradigm shifts][35] for key [historic][229] events shows an [exponential][230] trend.[_[clarification needed][231]_] The lists' compilers include [Carl Sagan][232][_[citation needed][147]_], [Paul D. Boyer][233], _[Encyclopædia Britannica][234]_, [American Museum of Natural History][235], and [University of Arizona][236]. Click to enlarge.

Main article: [Accelerating change][110]

Some singularity proponents argue its inevitability through extrapolation of 
past trends, especially those pertaining to shortening gaps between improvements 
to technology. In one of the first uses of the term "singularity" in the context 
of technological progress, Stanislaw [Ulam (1958][237]) tells of a conversation 
with [John von Neumann][98] about accelerating change:

> 
> One conversation centered on the ever accelerating progress of technology and 
> changes in the mode of human life, which gives the appearance of approaching 
> some essential singularity in the history of the race beyond which human affairs, 
> as we know them, could not continue.
> 

[Hawkins (1983][238]) writes that "mindsteps", dramatic and irreversible changes 
to paradigms or world views, are accelerating in frequency as quantified in 
his mindstep equation. He cites the inventions of writing, mathematics, and 
the computer as examples of such changes.

Ray Kurzweil's analysis of history concludes that technological progress follows 
a pattern of [exponential growth][230], following what he calls _The Law of 
Accelerating Returns_. He generalizes Moore's law, which describes geometric 
growth in integrated semiconductor complexity, to include technologies from 
far before the integrated circuit.

Whenever technology approaches a barrier, Kurzweil writes, new technologies 
will surmount it. He predicts [paradigm shifts][35] will become increasingly 
common, leading to "technological change so rapid and profound it represents 
a rupture in the fabric of human history".([Kurzweil 2001][239]) Kurzweil believes 
that the singularity will occur before the end of the 21st century, setting 
the [date at 2045][240] ([Kurzweil 2005][241]). His predictions differ from 
Vinge’s in that he predicts a gradual ascent to the singularity, rather than 
Vinge’s rapidly self-improving superhuman intelligence.

This leads to the conclusion that an artificial intelligence capable of improving 
on its own design is itself faced with a singularity.[_[citation needed][147]_] 
Self-augmentation or bootstrapping of intelligence is featured by [Dan Simmons][242] 
in his novel _[Hyperion][243]_, where a collection of artificial intelligences 
debate whether or not to make themselves obsolete by creating a new generation 
of "ultimate" intelligence.[_[citation needed][147]_]

Presumably, a technological singularity would lead to rapid development of 
a [Kardashev Type I civilization][244], where a Kardashev Type I civilization 
is one that has achieved mastery of the resources of its home planet, Type 
II of its [planetary system][245], and Type III of its [galaxy][246].[[71]][247] 

Oft-cited dangers include those commonly associated with [molecular nanotechnology][49] 
and [genetic engineering][157]. These threats are major issues for both singularity 
advocates and critics, and were the subject of [Bill Joy][122]'s _[Wired][248]_ 
magazine article "[Why the future doesn't need us][249]".([Joy 2000][250]) 

The [Acceleration Studies Foundation][251], an educational non-profit foundation 
founded by [John Smart][252], engages in outreach, education, research and 
advocacy concerning accelerating change.([Acceleration Studies Foundation 2007][253]) 
It produces the Accelerating Change conference at Stanford University, and 
maintains the educational site [Acceleration Watch][254].

##  [[edit][255]] Criticism 

[Steven Pinker][256] stated in 2008:[[25]][86]

> 
> "(...) There is not the slightest reason to believe in a coming singularity. 
> The fact that you can visualize a future in your imagination is not evidence 
> that it is likely or even possible. Look at domed cities, jet-pack commuting, 
> underwater cities, mile-high buildings, and nuclear-powered automobiles — all 
> staples of futuristic fantasies when I was a child that have never arrived. 
> Sheer processing power is not a pixie dust that magically solves all your problems. 
> (...)"
> 

Some critics assert that no computer or machine will ever achieve human intelligence, 
while others hold that the definition of intelligence is irrelevant if the 
net result is the same.[[72]][257]

Martin Ford in _The Lights in the Tunnel: Automation, Accelerating Technology 
and the Economy of the Future_ [[73]][258] postulates a "technology paradox" 
in that before the Singularity could occur, most routine jobs in the economy 
would be automated since this would require a level of technology inferior 
to that of the Singularity. This would cause massive unemployment and plummeting 
consumer demand—which in turn would destroy the incentive to invest in the 
technologies that would be required to bring about the Singularity. Job displacement 
is increasingly no longer limited to work traditionally considered to be "routine."[[74]][259] 

[Jared Diamond][260] in _[Collapse: How Societies Choose to Fail or Succeed][261]_ 
shows that cultures self-limit when they exceed the sustainable carrying capacity 
of their environment, and the consumption of strategic resources (frequently 
timber, soils or water) creates a deleterious positive feedback loop that leads 
eventually to social collapse and technological retrogression.

###  [[edit][262]] Criticism of the accelerating returns argument 

[Theodore Modis][263][[75]][264][[76]][265] and [Jonathan Huebner][266][[77]][267] 
argue that the rate of technological innovation has not only ceased to rise, 
but is actually now declining ([John Smart][252], however, criticizes Huebner's 
analysis.[[78]][268]) Some evidence for this decline is that the rise in computer 
[clock rates][269] is slowing, even while Moore's prediction of exponentially 
increasing circuit density continues to hold. This is due to excessive heat 
build-up from the chip, which cannot be dissipated quickly enough to prevent 
the chip from melting when operating at higher speeds. Advancements in speed 
may be possible in the future by virtue of more power-efficient CPU designs 
and multi-cell processors.[[79]][270] While Kurzweil used Modis' resources, 
and Modis' work was around accelerating change, Modis' distanced himself from 
Kurzweil's thesis of there being a "technological singularity", claiming that 
it lacks scientific rigor.[[76]][265]

Others propose that other "singularities" can be found through analysis of 
trends in [world population][271], world [gross domestic product][272], and 
other indices. [Andrey Korotayev][273] and others argue that historical [hyperbolic 
growth][274] curves can be attributed to [feedback loops][119] that ceased 
to affect global trends in the 1970s, and thus hyperbolic growth should not 
be expected in the future.[[80]][275][[81]][276]

In _The Progress of Computing_, [William Nordhaus][277] argued that, prior 
to 1940, computers followed the much slower growth of a traditional industrial 
economy, thus rejecting extrapolations of Moore's law to 19th-century computers. 
[Schmidhuber (2006][278]) suggests differences in memory of recent and distant 
events create an illusion of accelerating change, and that such phenomena may 
be responsible for past apocalyptic predictions.

Andrew Kennedy, in his 2006 paper for the [British Interplanetary Society][279] 
discussing [change and the growth in space travel velocities][280],[[82]][281] 
stated that although long-term overall growth is inevitable, it is small, embodying 
both ups and downs, and noted, "New technologies follow known laws of power 
use and information spread and are obliged to connect with what already exists. 
Remarkable theoretical discoveries, if they end up being used at all, play 
their part in maintaining the growth rate: they do not make its plotted curve... 
redundant." He stated that exponential growth is no predictor in itself, and 
illustrated this with examples such as [quantum theory][282]. The quantum was 
conceived in 1900, and quantum theory was in existence and accepted approximately 
25 years later. However, it took over 40 years for [Richard Feynman][283] and 
others to produce meaningful numbers from the theory. [Bethe][284] understood 
nuclear fusion in 1935, but 75 years later fusion reactors are still only used 
in experimental settings. Similarly, [entanglement][285] was understood in 
1935 but not at the point of being used in practice until the 21st century. 

A study of patents per thousand persons shows that human creativity does not 
show accelerating returns, but in fact—as suggested by [Joseph Tainter][286] 
in his seminal _The Collapse of Complex Societies_[[83]][287]—a law of diminishing 
returns. The number of patents per thousand peaked in the period from 1850–1900, 
and has been declining since.[[77]][267] The growth of complexity eventually 
becomes self-limiting, and leads to a wide spread "general systems collapse". 
[Thomas Homer Dixon][288] in _[The Upside of Down: Catastrophe, Creativity 
and the Renewal of Civilization][289]_ maintains that the declining energy 
returns on investment has led to the collapse of civilizations.

In addition to general criticisms of the singularity concept, several critics 
have raised issues with Kurzweil's iconic chart. One line of criticism is that 
a log-log chart of this nature is inherently biased toward a straight-line 
result. Others identify selection bias in the points that Kurzweil chooses 
to use. For example, biologist [PZ Myers][290] points out that many of the 
early evolutionary "events" were picked arbitrarily.[[84]][291] Kurzweil has 
rebutted this by charting evolutionary events from 15 neutral sources, and 
showing that they fit a straight line on [a log-log chart][227].

_[The Economist][292]_ mocked the concept with a graph extrapolating that the 
number of blades on a razor, which has increased over the years from one to 
as many as five, will increase ever-faster to infinity.[[85]][293]

##  [[edit][294]] In popular culture 

 See also: [List of fictional computers][295]

[Isaac Asimov][218]'s 1950 story "[The Evitable Conflict][296]", (the last 
part of the _[I, Robot][297]_ collection) features the Machines, four supercomputers 
managing the world's economy. The computers are incomprehensible to humans 
and are impossible to analyze for errors, having been created through 10 stages 
of [bootstrapping][298]. In the end of the story, it is implied that from now 
on (it occurs in 2052), no major conflict can occur, and the Machines are going 
to guide humanity toward a better future, one only they are capable of seeing 
(and know to truly be the best). [Susan Calvin][299] states that "For all time, 
all conflicts are finally evitable. Only the Machines, from now on, are inevitable!" 

[James P. Hogan][300]'s 1979 novel _The Two Faces of Tomorrow_ is an explicit 
description of what is now called the Singularity. An artificial intelligence 
system solves an excavation problem on the moon in a brilliant and novel way, 
but nearly kills a work crew in the process. Realizing that systems are becoming 
too sophisticated and complex to predict or manage, a scientific team sets 
out to teach a sophisticated computer network how to think more humanly. The 
story documents the rise of self-awareness in the computer system, the humans' 
loss of control and failed attempts to shut down the experiment as the computer 
desperately defends itself, and the computer intelligence reaching maturity. 

While discussing the singularity's growing recognition, Vernor Vinge wrote 
in 1993 that "it was the science-fiction writers who felt the first concrete 
impact." In addition to his own short story "Bookworm, Run!", whose protagonist 
is a chimpanzee with intelligence augmented by a government experiment, he 
cites [Greg Bear][301]'s novel _[Blood Music][302]_ (1983) as an example of 
the singularity in fiction. Vinge described surviving the singularity in his 
1986 novel _[Marooned in Realtime][108]_. Vinge later expanded the notion of 
the singularity to a galactic scale in _[A Fire Upon the Deep][109]_ (1992), 
a novel populated by transcendent beings, each the product of a different race 
and possessed of distinct agendas and overwhelming power.

In [William Gibson][303]'s 1984 novel _[Neuromancer][304]_, artificial intelligences 
capable of improving their own programs are strictly regulated by special "Turing 
police" to ensure they never exceed a certain level of intelligence, and the 
plot centers on the efforts of one such AI to circumvent their control. The 
1994 novel _[The Metamorphosis of Prime Intellect][305]_ features an AI that 
augments itself so quickly as to gain low-level control of all matter in the 
universe in a matter of hours.

[William Gibson][303] and [Bruce Sterling][306]'s [alternate history][307] 
[Steampunk][308] novel _[The Difference Engine][309]_ ends with a vision of 
the singularity occurring in 1991 with a superintelligent computer that has 
merged its mind with the inhabitants of London.

A more malevolent AI achieves similar levels of omnipotence in [Harlan Ellison][310]'s 
short story _[I Have No Mouth, and I Must Scream][311]_ (1967).

[William Thomas Quick][312]'s novels _Dreams of Flesh and Sand_ (1988), _Dreams 
of Gods and Men_ (1989), and _Singularities_ (1990) present an account of the 
transition through the singularity; in the last novel, one of the characters 
states that mankind's survival requires it to integrate with the emerging machine 
intelligences, or it will be crushed under the dominance of the machines – 
the greatest risk to the survival of a species reaching this point (and alluding 
to large numbers of other species that either survived or failed this test, 
although no actual contact with alien species occurs in the novels).

The singularity is sometimes addressed in fictional works to explain the event's 
absence. [Neal Asher][313]'s _[Gridlinked][314]_ series features a future where 
humans living in the Polity are governed by AIs and while some are resentful, 
most believe that they are far better governors than any human. In the fourth 
novel, _[Polity Agent][315]_, it is mentioned that the singularity is far overdue 
yet most AIs have decided not to partake in it for reasons that only they know. 
A flashback character in [Ken MacLeod][316]'s 1998 novel _The Cassini Division_ 
dismissively refers to the singularity as "the [Rapture][317] for nerds", though 
the singularity goes on to happen anyway.

Popular movies in which computers become intelligent and violently overpower 
the human race include _[Colossus: The Forbin Project][318]_, the _[Terminator][319]_ 
series, the very loose film adaptation of _[I, Robot][221]_, and _[The Matrix][320]_ 
series. The television series _[Battlestar Galactica][321]_ also explores these 
themes.

[Isaac Asimov][218] expressed ideas similar to a post-Kurzweilian singularity 
in his short story "[The Last Question][322]". Asimov's future envisions a 
reality where a combination of [strong artificial intelligence][323] and [post-humans][324] 
consume the cosmos, during a time Kurzweil describes as when "the universe 
wakes up", the last of his six stages of cosmic evolution as described in _[The 
Singularity is Near][125]_. Post-human entities throughout various time periods 
of the story inquire of the artificial intelligence within the story as to 
how [entropy death][325] will be avoided. The AI responds that it lacks sufficient 
information to come to a conclusion, until the end of the story when the AI 
does indeed arrive at a solution. Notably, it does so in order to fulfill its 
[duty][219] to answer the humans' question.

[St. Edward's University][326] chemist [Eamonn Healy][327] discusses accelerating 
change in the film _[Waking Life][328]_. He divides history into increasingly 
shorter periods, estimating "two billion years for life, six million years 
for the hominid, a hundred-thousand years for mankind as we know it". He proceeds 
to human cultural evolution, giving time scales of ten thousand years for agriculture, 
four hundred years for the scientific revolution, and one hundred fifty years 
for the industrial revolution. Information is emphasized as providing the basis 
for the new evolutionary paradigm, with artificial intelligence its culmination. 
He concludes we will eventually create "neohumans" which will usurp humanity’s 
present role in scientific and technological progress and allow the exponential 
trend of accelerating change to continue past the limits of human ability. 

Accelerating progress features in some science fiction works, and is a central 
theme in [Charles Stross][329]'s [_Accelerando_][330]. Other notable authors 
that address singularity-related issues include [Karl Schroeder][331], [Greg 
Egan][332], [Ken MacLeod][316], [Rudy Rucker][333], [David Brin][334], [Iain 
M. Banks][335], [Neal Stephenson][336], [Tony Ballantyne][337], [Bruce Sterling][306], 
[Dan Simmons][242], [Damien Broderick][120], [Fredric Brown][338], [Jacek Dukaj][339], 
[Stanislav Lem][340], [Nagaru Tanigawa][341], [Douglas Adams][342], [Michael 
Crichton][343] and [Ian McDonald][344].

The feature-length documentary film _[Transcendent Man][129]_ by [Barry Ptolemy][128] 
is based on Kurzweil and his book _The Singularity Is Near_. The film documents 
Kurzweil's quest to reveal what he believes to be mankind's destiny. Another 
documentary, _[Plug & Pray][345]_, focuses on the promise, problems and ethics 
of artificial intelligence and robotics, with [Joseph Weizenbaum][346] and 
Kurzweil as the main subjects of the film.[[86]][347]

In 2009, scientists at Aberystwyth University in Wales and the U.K's University 
of Cambridge designed a robot called Adam that they believe to be the first 
machine to independently discover new scientific findings.[[87]][348] Also 
in 2009, researchers at [Cornell][349] developed a computer program that extrapolated 
the laws of motion from a pendulum's swings.[[88]][350][[89]][351]

The web comic [Dresden Codak][352] deals with trans-humanistic themes and the 
singularity.

The plot of an episode of the TV program _[The Big Bang Theory][353]_ (season 4, 
episode 2, "The Cruciferous Vegetable Amplification") revolves around the anticipated 
date of the coming Singularity.

The seventeenth episode of the sixth season of the TV sitcom Futurama, Benderama 
references Bender reaching the technological singularity and being able to 
infinitely produce smaller versions of himself to wreak havoc on the world. 

[Industrial][354]/[Steampunk][308] entertainer [Doctor Steel][355] weaves the 
concept of a technological singularity into his music and videos, even having 
a song entitled _The Singularity_. He has been interviewed on his views by 
the [Institute for Ethics and Emerging Technologies][356],[[90]][357] and has 
also authored a paper on the subject.[[91]][358][[92]][359]

In 2012, concept band [SOLA-MI][360], released "NEXUS (Original Motion Picture 
Soundtrack)," an album about the first waking machine.

##  [[edit][361]] See also 

|

* [Democratic Transhumanism][362]
* [Development criticism][363]
* [Doomsday argument][364]
* [Erewhon][95]
* [Eschatology#Empirical and Rationalist based][365]
* [Hyperbolic growth][274]
* [List of emerging technologies][366]
* 
[Logarithmic timeline][367] and [detailed logarithmic timeline][368]

* [Mind uploading][160]
* [Molecular engineering][369]
* [Novelty theory][370]
* [Omega Point][371]
* [Positive feedback][372]

|
|[![Portal icon][373]][374]|[Sustainable development portal][375]|

* [Post Scarcity][376]
* [Predictive medicine][377]
* [Sentience quotient][378]
* [Simulated reality][379]
* [Singularitarianism][215]
* [The Singularity Is Near][380]
* [Technocapitalism][381]
* [Technological determinism][382]
* [Technological evolution][383]
* [Techno-utopianism][384]
* [Tipping point][385]
* [Transcendent Man][386]
* [Transhumanism][387]

|

##  [[edit][388]] Notes 

1. 
**[^][389]** Superintelligence. Answer to the 2009 EDGE QUESTION: "WHAT WILL CHANGE EVERYTHING?": [http://www.nickbostrom.com/views/superintelligence.pdf][390]

2.  ^ [_**a**_][391] [_**b**_][392] David Chalmers on Singularity, Intelligence Explosion. April 8th, 2010. Singularity Institute for Artificial Intelligence: [http://singinst.org/blog/2010/04/08/david-chalmers-on-singularity-intelligence-explosion/][393]

3. 
**[^][394]** Editor's Blog Why an Intelligence Explosion is Probable By: Richard Loosemore and Ben Goertzel. March 7, 2011; hplusmagazine: [http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/][395]

4.  ^ [_**a**_][396] [_**b**_][397] [_**c**_][398] Vinge, Vernor. ["The Coming Technological Singularity: How to Survive in the Post-Human Era"][399], originally in _Vision-21: Interdisciplinary Science and Engineering in the Era of Cyberspace_, G. A. Landis, ed., NASA Publication CP-10129, pp. 115-126, 1993 
5. 
**[^][400]** Ray Kurzweil, The Singularity is Near, pp. 135-136. Penguin Group, 2005. 
6.  ^ [_**a**_][401] [_**b**_][402] [_**c**_][403] [_**d**_][404] ["What is the Singularity? | Singularity Institute for Artificial Intelligence"][405]. Singinst.org. [http://singinst.org/overview/whatisthesingularity][405]. Retrieved 2011-09-09.  
7. 
**[^][406]** ["h+ Magazine | Covering technological, scientific, and cultural trends that are changing human beings in fundamental ways"][407]. Hplusmagazine.com. [http://www.hplusmagazine.com/articles/nano/singularity-nanotech-or-ai][407]. Retrieved 2011-09-09.  
8.  ^ [_**a**_][408] [_**b**_][409] [_**c**_][410] [Yudkowsky, Eliezer][130]. [The Singularity: Three Major Schools][411]

9. 
**[^][412]** [Sandberg, Anders][191]. [An overview of models of technological singularity][413]

10.  ^ [_**a**_][414] [_**b**_][415] ["Max More and Ray Kurzweil on the Singularity"][416]. KurzweilAI. [http://www.kurzweilai.net/max-more-and-ray-kurzweil-on-the-singularity-2][416]. Retrieved 2011-09-09.  
11. 
**[^][417]** Good, I. J. ["Speculations Concerning the First Ultraintelligent Machine"][418], _Advances in Computers_, vol. 6, 1965. 
12. 
**[^][419]** Ehrlich, Paul. [The Dominant Animal: Human Evolution and the Environment][420]

13. 
**[^][421]** [Superbrains born of silicon will change everything.][422]

14. 
**[^][423]** Good, I. J., "Speculations Concerning the First Ultraintelligent Machine", Franz L. Alt and Morris Rubinoff, ed., Advances in Computers (Academic Press) 6: 31–88, 1965. 
15. 
**[^][424]** [The Human Importance of the Intelligence Explosion][425]

16. 
**[^][426]** Good, I. J. 1965 Speculations Concerning the First Ultraintelligent Machine. Pp 31-88 in Advances in Computers, 6, F. L. Alt and M Rubinoff, eds. New York: Academic Press. 
17. 
**[^][427]** Ray Kurzweil, _The Age of Spiritual Machines_, Viking, 1999, [p. 30][428] and [p. 32][429]

18. 
**[^][430]** Ray Kurzweil, _The Singularity is Near_, Penguin Group, 2005 
19. 
**[^][431]** Ray Kurzweil, The Singularity is Near, p. 9. Penguin Group, 2005 
20. 
**[^][432]** Ray Kurzweil, _The Singularity is Near_, pp. 135-136. Penguin Group, 2005. The context for this statement is as follows: "we will be producing about 1026 to 1029 cps of nonbiological computation per year in the early 2030s. This is roughly equal to our estimate for the capacity of all living biological human intelligence ... This state of computation in the early 2030s will not represent the Singularity, however, because it does not yet correspond to a profound expansion of our intelligence. By the mid-2040s, however, that one thousand dollars' worth of computation will be equal to 1026 cps, so the intelligence created per year (at a total cost of about $1012) will be about one billion times more powerful than all human intelligence today. That _will_ indeed represent a profound change, and it is for that reason that I set the date for the Singularity—representing a profound and disruptive transformation in human capability—as 2045." 
21.  ^ [_**a**_][433] [_**b**_][434] [_**c**_][435] [_**d**_][436] Yudkowsky, Eliezer (2008), Bostrom, Nick; Cirkovic, Milan, eds., ["Artificial Intelligence as a Positive and Negative Factor in Global Risk"][437], _Global Catastrophic Risks_ (Oxford University Press): 303, [Bibcode][438] [2008gcr..book..303Y][439], [ISBN][440] [978-0-19-857050-9][441], [http://singinst.org/AIRisk.pdf][437]  
22. 
**[^][442]** [The Uncertain Future; a future technology and world-modeling project][443]

23. 
**[^][444]** [GLOBAL CATASTROPHIC RISKS SURVEY (2008) Technical Report 2008/1 Published by Future of Humanity Institute, Oxford University. Anders Sandberg and Nick Bostrom][445]

24. 
**[^][446]** [Existential Risks; Analyzing Human Extinction Scenarios and Related Hazards, Nick Bostrom][447]

25.  ^ [_**a**_][448] [_**b**_][449] ["Tech Luminaries Address Singularity - IEEE Spectrum"][450]. Spectrum.ieee.org. [http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity][450]. Retrieved 2011-09-09.  
26. 
**[^][451]** ["Who's Who In The Singularity - IEEE Spectrum"][452]. Spectrum.ieee.org. [http://spectrum.ieee.org/computing/hardware/whos-who-in-the-singularity][452]. Retrieved 2011-09-09.  
27. 
**[^][453]** Thornton, Richard (1847), [_The Expounder of Primitive Christianity_][454], **4**, Ann Arbor, Michigan, p. 281, [http://books.google.com/?id=ZM_hAAAAMAAJ&dq=%22Primitive%20Expounder%22%20thornton%201847&pg=PA281#v=onepage&q=thinking%20machine&f=false][454]  
28. 
**[^][455]** A M Turing, _Intelligent Machinery, A Heretical Theory_, 1951, reprinted _Philosophia Mathematica_ (1996) 4(3): 256-260 [doi][456]:[10.1093/philmat/4.3.256][457] [[1]][458]

29. 
**[^][459]** Ulam, S., Tribute to John von Neumann, Bulletin of the American Mathematical Society, vol 64, nr 3, part 2, May, 1958, p1-49. 
30. 
**[^][460]** Dooling, Richard. _Rapture for the Geeks: When AI Outsmarts IQ_ (2008), [p. 88][461]

31. 
**[^][462]** Vinge did not actually use the phrase "technological singularity" in the Omni op-ed, but he did use this phrase in the short story collection _Threats and Other Promises_ from 1988, writing in the introduction to his story "The Whirligig of Time" (p. 72): _Barring a worldwide catastrophe, I believe that technology will achieve our wildest dreams, and_ soon. _When we raise our own intelligence and that of our creations, we are no longer in a world of human-sized characters. At that point we have fallen into a technological "black hole," a technological singularity._

32. 
**[^][463]** Solomonoff, R.J. "The Time Scale of Artificial Intelligence: Reflections on Social Effects," Human Systems Management, Vol 5, pp. 149-153, 1985, [http://world.std.com/~rjs/timesc.pdf][464]. 
33. 
**[^][465]** Moravec, Hans (1998), ["When will computer hardware match the human brain?"][466], _Journal of Evolution and Technology_ **1**, [http://www.transhumanist.com/volume1/moravec.htm][466], retrieved 2006-06-23.  
34. 
**[^][467]** Moravec, Hans (June 1993). ["The Age of Robots"][468]. [http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html][468]. Retrieved 2006-06-23.  
35. 
**[^][469]** Moravec, Hans (April 2004). ["Robot Predictions Evolution"][470]. [http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2004/Predictions.html][470]. Retrieved 2006-06-23.  
36. 
**[^][471]** Dooling, Richard. _Rapture for the Geeks: When AI Outsmarts IQ_ (2008), [p. 89][472]

37. 
**[^][473]** [The Coming Technological Singularity: How to Survive in the Post-Human Era][399], by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge. 
38. 
**[^][474]** [Joy, Bill][122] (April 2000), ["Why the future doesn’t need us"][475], _[Wired Magazine][248]_ (Viking Adult) (8.04), [ISBN][440] [0-670-03249-2][476], [http://www.wired.com/wired/archive/8.04/joy.html][475], retrieved 2007-08-07  
39. 
**[^][477]** [_Episode dated 23 August 2006_][478] at the [Internet Movie Database][479]

40.  ^ [_**a**_][480] [_**b**_][481] Robin Hanson, ["Economics Of The Singularity"][482], _IEEE Spectrum Special Report: The Singularity_, [http://www.spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity][482], retrieved 2008-09-11  & [Long-Term Growth As A Sequence of Exponential Modes][483]

41. 
**[^][484]** [About Singularity University][485] at its official website 
42. 
**[^][486]** [de Grey, Aubrey][148]. [The singularity and the Methuselarity: similarities and differences][487][_[dead link][488]_]
43. 
**[^][489]** Geraci, Robert M., _Apocalyptic AI - Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality_, [ISBN][440] [978-0-19-539302-6][490]  
44. 
**[^][491]** [2045: The Year Man Becomes Immortal][492], By Lev Grossman Thursday, Feb. 10, 2011 time.com. 
45. 
**[^][493]** [[2]][494] David Chalmers John Locke Lecture, 10 May, Exam Schools, Oxford, presenting a philosophical analysis of the possibility of a technological singularity or "intelligence explosion" resulting from recursively self-improving AI. 
46. 
**[^][495]** [The Singularity: A Philosophical Analysis, David J. Chalmers][496]

47. 
**[^][497]** ["ITRS"][498] (PDF). [http://www.itrs.net/Links/2007ITRS/ExecSum2007.pdf][498]. Retrieved 2011-09-09.  
48. 
**[^][499]** Siracusa, John (2009-08-31). ["Mac OS X 10.6 Snow Leopard: the Ars Technica review"][500]. Arstechnica.com. [http://arstechnica.com/apple/reviews/2009/08/mac-os-x-10-6.ars/8][500]. Retrieved 2011-09-09.  
49. 
**[^][501]** Eliezer Yudkowsky, 1996 "Staring at the Singularity 
50. 
**[^][502]** Eliezer S. Yudkowsky. ["Power of Intelligence"][503]. Yudkowsky. [http://yudkowsky.net/singularity/power][503]. Retrieved 2011-09-09.  
51. 
**[^][504]** [Omohundro, Stephen M., "The Basic AI Drives." Artificial General Intelligence, 2008 proceedings of the First AGI Conference, eds. Pei Wang, Ben Goertzel, and Stan Franklin. Vol. 171. Amsterdam: IOS, 2008][505]

52. 
**[^][506]** ["Artificial General Intelligence: Now Is the Time"][507]. KurzweilAI. [http://www.kurzweilai.net/artificial-general-intelligence-now-is-the-time][507]. Retrieved 2011-09-09.  
53.  ^ [_**a**_][508] [_**b**_][509] [Omohundro, Stephen M., "The Nature of Self-Improving Artificial Intelligence." Self-Aware Systems. 21 Jan. 2008. Web. 07 Jan. 2010.][510]

54.  ^ [_**a**_][511] [_**b**_][512] ["Concise Summary | Singularity Institute for Artificial Intelligence"][513]. Singinst.org. [http://singinst.org/riskintro/index.html][513]. Retrieved 2011-09-09.  
55.  ^ [_**a**_][514] [_**b**_][515] [Bostrom, Nick, The Future of Human Evolution, Death and Anti-Death: Two Hundred Years After Kant, Fifty Years After Turing, ed. Charles Tandy, p. 339–371, 2004, Ria University Press.][516]

56. 
**[^][517]** [Ethical Issues in Advanced Artificial Intelligence, Nick Bostrom, in Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, Vol. 2, ed. I. Smit et al., Int. Institute of Advanced Studies in Systems Research and Cybernetics, 2003, pp. 12-17][518]

57. 
**[^][519]** [Eliezer Yudkowsky][130]: [Artificial Intelligence as a Positive and Negative Factor in Global Risk][520]. Draft for a publication in _Global Catastrophic Risk_ from August 31, 2006, retrieved July 18, 2011 (PDF file) 
58. 
**[^][521]** [The Stamp Collecting Device, Nick Hay][522]

59. 
**[^][523]** ['Why we should fear the Paperclipper'][524], 2011-02-14 entry of Sandberg's blog 'Andart' 
60. 
**[^][525]** [Omohundro, Stephen M., "The Basic AI Drives." Artificial General Intelligence, 2008 proceedings of the First AGI Conference, eds. Pei Wang, Ben Goertzel, and Stan Franklin. Vol. 171. Amsterdam: IOS, 2008.][505]

61. 
**[^][526]** de Garis, Hugo. ["The Coming Artilect War"][527], Forbes.com, 22 June 2009. 
62. 
**[^][528]** [Artificial Intelligence Will Kill Our Grandchildren (Singularity), Dr Anthony Berglas][529]

63. 
**[^][530]** The Singularity: A Philosophical Analysis David J. Chalmers 
64. 
**[^][531]** [Coherent Extrapolated Volition, Eliezer S. Yudkowsky, May 2004][532]

65. 
**[^][533]** [Scientists Worry Machines May Outsmart Man][534] By JOHN MARKOFF, NY Times, July 26, 2009. 
66. 
**[^][535]** [Call for debate on killer robots][536], By Jason Palmer, Science and technology reporter, BBC News, 8/3/09. 
67. 
**[^][537]** Mick, Jason. [New Navy-funded Report Warns of War Robots Going "Terminator"][538], Blog, dailytech.com, February 17, 2009. 
68. 
**[^][539]** Flatley, Joseph L. [Navy report warns of robot uprising, suggests a strong moral compass][540], engadget.com, 18 February 2009. 
69. 
**[^][541]** [AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study][542], Association for the Advancement of Artificial Intelligence, Accessed 7/26/09. 
70. 
**[^][543]** [Article at Asimovlaws.com][544], July 2004, accessed 7/27/2009. 
71. 
**[^][545]** Zubrin, Robert. 1999, _Entering Space - Creating a Spacefaring Civilization_

72. 
**[^][546]** [Dreyfus & Dreyfus 2000][547], p. xiv: 

	> 
	> "(...) The truth is that human intelligence can never be replaced with machine 
	> intelligence simply because we are not ourselves "thinking machines" in the 
	> sense in which that term is commonly understood.[Hawking (1998][548]) (...)" 
	> 

  : 

	> 
	> Some people say that computers can never show true intelligence whatever that 
	> may be. But it seems to me that if very complicated chemical molecules can 
	> operate in humans to make them intelligent then equally complicated electronic 
	> circuits can also make computers act in an intelligent way. And if they are 
	> intelligent they can presumably design computers that have even greater complexity 
	> and intelligence.
	> 

73. 
**[^][549]** Ford, Martin, _[The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future][550]_, Acculant Publishing, 2009, [ISBN 978-1-4486-5981-4][551]

74. 
**[^][552]** Markoff, John (2011-03-04). ["Armies of Expensive Lawyers, Replaced by Cheaper Software"][553]. _The New York Times_. [http://www.nytimes.com/2011/03/05/science/05legal.html][553].  
75. 
**[^][554]** Theodore Modis, [Forecasting the Growth of Complexity and Change][555], _Technological Forecasting & Social Change_, 69, No 4, 2002 
76.  ^ [_**a**_][556] [_**b**_][557] [Modis, Theodore. _The Singularity Myth_][558]

77.  ^ [_**a**_][559] [_**b**_][560] Huebner, Jonathan (2005) A Possible Declining Trend for Worldwide Innovation, _Technological Forecasting & Social Change_, October 2005, pp. 980-6 
78. 
**[^][561]** Smart, John (September 2005), On Huebner Innovation, Acceleration Studies Foundation, [http://accelerating.org/articles/huebnerinnovation.html][562], retrieved on 2007-08-07 
79. 
**[^][563]** Krazit, Tom. [Intel pledges 80 cores in five years][564], _CNET News_, 26 September 2006. 
80. 
**[^][565]** See, e.g., Korotayev A., Malkov A., Khaltourina D. [_Introduction to Social Macrodynamics: Compact Macromodels of the World System Growth_][566]. Moscow: URSS Publishers, 2006; Korotayev A. V. [A Compact Macromodel of World System Evolution // Journal of World-Systems Research 11/1 (2005): 79–93.][567]

81. 
**[^][568]** For a detailed mathematical analysis of this issue see [A Compact Mathematical Model of the World System Economic and Demographic Growth, 1 CE - 1973 CE][569]. 
82. 
**[^][570]** Interstellar Travel: The Wait Calculation and the Incentive Trap of Progress, JBIS Vol 59, N.7 July 2006 
83. 
**[^][571]** Tainter, Joseph (1988) "The Collapse of Complex Societies" (Cambridge University Press) 
84. 
**[^][572]** Myers, PZ, [_Singularly Silly Singularity_][573], [http://scienceblogs.com/pharyngula/2009/02/singularly_silly_singularity.php][573], retrieved 2009-04-13  
85. 
**[^][574]** Anonymous (18 March 2006), ["More blades good"][575], _The Economist_ (London) **378** (8469): 85, [http://www.economist.com/science/displaystory.cfm?story_id=5624861][575]  
86. 
**[^][576]** [Plug & Pray][577] Documentary film (2010) about the promise, problems and ethics of artificial intelligence and robotics 
87. 
**[^][578]** [Robo-scientist makes gene discovery-on its own | Crave - CNET][579]

88. 
**[^][580]** Keim, Brandon (2009-04-02). ["Computer Program Self-Discovers Laws of Physics"][581]. _Wired_. [http://www.wired.com/wiredscience/2009/04/newtonai/][581].  
89. 
**[^][582]** [Cornell Chronicle: Computer derives natural laws][583]

90. 
**[^][584]** Michael Anissimov. ["Interview with Dr. Steel"][585]. Institute for Ethics and Emerging Technologies. [http://ieet.org/index.php/IEET/more/2572/][585]. Retrieved 2009-08-29.  
91. 
**[^][586]** Dr. Steel (Spring 2005). ["Multi-Media Symbiosis and the Evolution of Electronic Life"][587]. Paranoia: The Conspiracy Reader, Issue 38 (back issue). [http://www.paranoiamagazine.com/backissues.html][587]. Retrieved 2010-04-16.  
92. 
**[^][588]** Dr. Steel (Spring 2005). ["Multi-Media Symbiosis and the Evolution of Electronic Life"][589]. _World Domination Toys_ (clipping from Paranoia: The Conspiracy Reader). [http://worlddominationtoys.com/drsteel/clippings_paranoia.html][589]. Retrieved 2010-04-16.  

##  [[edit][590]] References 

*  Acceleration Studies Foundation (2007), [_ASF: About the Foundation_][591], [http://www.accelerating.org/about.html][591], retrieved 2007-11-13  
*  Anonymous (18 March 2006), ["More blades good"][575], _The Economist_ (London) **378** (8469): 85, [http://www.economist.com/science/displaystory.cfm?story_id=5624861][575]  
* 
[Bell, James John][592] (2002), [_Technotopia and the Death of Nature: Clones, Supercomputers, and Robots_][593], Earth Island Journal (first published in the November/December 2001 issue of the _Earth First! Journal_), [http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/][593], retrieved 2007-08-07  
*  Bell, James John (1 May 2003), ["Exploring The "Singularity""][594], _The Futurist_ ([World Future Society][595] (mindfully.org)), [http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm][594], retrieved 2007-08-07  
*  Berglas, Anthony (2008), [_Artificial Intelligence will Kill our Grandchildren_][596], [http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html][596], retrieved 2008-06-13  
* 
[Broderick, Damien][120] (2001), _The Spike: How Our Lives Are Being Transformed by Rapidly Advancing Technologies_, New York: Forge, [ISBN][440] [0-312-87781-1][597]  
* 
[Bostrom, Nick][187] (2002), ["Existential Risks"][447], _[Journal of Evolution and Technology][598]_ **9**, [http://www.nickbostrom.com/existential/risks.html][447], retrieved 2007-08-07  
*  Bostrom, Nick (2003), ["Ethical Issues in Advanced Artificial Intelligence"][518], _Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence_ **2**: 12–17, [http://www.nickbostrom.com/ethics/ai.html][518], retrieved 2007-08-07  
* 
[Dreyfus, Hubert L.][599]; [Dreyfus, Stuart E.][600] (1 March 2000), _Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer_ (1 ed.), New York: Free Press, [ISBN][440] [0-7432-0551-0][601]  
*  Ford, Martin (2009), [_The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future_][550], CreateSpace, [ISBN][440] [978-1-4486-5981-4][602], [http://www.thelightsinthetunnel.com][550].  
* 
[Good, I. J.][55] (1965), Franz L. Alt and Morris Rubinoff, ed., ["Speculations Concerning the First Ultraintelligent Machine"][603], _Advances in Computers_ ([Academic Press][604]) **6**: 31–88, archived from [the original][605] on 2001-05-27, [http://web.archive.org/web/20010527181244/http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html][603], retrieved 2007-08-07  
* 
[Hanson, Robin][131] (1998), [_Some Skepticism_][606], Robin Hanson, [http://hanson.gmu.edu/vc.html#hanson][606], retrieved 2009-06-19 [_[dead link][488]_]
*  Hanson, Robin (June 2008), "Economics of the Singularity", _IEEE Spectrum_  
* 
[Hawking, Stephen][607] (1998), [_Science in the Next Millennium: Remarks by Stephen Hawking_][608], [http://clinton2.nara.gov/Initiatives/Millennium/shawking.html][608], retrieved 2007-11-13  
* 
[Hawkins, Gerald S.][609] (August 1983), _Mindsteps to the Cosmos_, HarperCollins, [ISBN][440] [0-06-015156-0][610]  
* 
[Heylighen, Francis][611] (2007), ["Accelerating Socio-Technological Evolution: from ephemeralization and stigmergy to the global brain"][612], in [Modelski][613], G.; Devezas, T.; Thompson, W., _Globalization as an Evolutionary Process: Modeling Global Change_, London: Routledge, [ISBN][440] [978-0-415-77361-4][614], [http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf][612]  
*  Johansen, Anders; Sornette, Didier (25 January 2001), ["Finite-time singularity in the dynamics of the world population, economic and financial indices"][615] (PDF), _Physica A_ **294** (3–4): 465–502, [DOI][456]:[10.1016/S0378-4371(01)00105-4][616], [http://hjem.get2net.dk/kgs/growthphysA.pdf][615], retrieved 2007-10-30  
* 
[Joy, Bill][122] (April 2000), ["Why the future doesn’t need us"][475], _[Wired Magazine][248]_ (Viking Adult) (8.04), [ISBN][440] [0-670-03249-2][476], [http://www.wired.com/wired/archive/8.04/joy.html][475], retrieved 2007-08-07  
* 
[Kurzweil, Raymond][617] (2001), [_The Law of Accelerating Returns_][618], Lifeboat Foundation, [http://lifeboat.com/ex/law.of.accelerating.returns][618], retrieved 2007-08-07  
*  Kurzweil, Raymond (2005), _[The Singularity Is Near][380]_, New York: Viking, [ISBN][440] [0-670-03384-7][619]  
* 
[Moravec, Hans][65] (January 1992), ["Pigs in Cyberspace"][620], _On the Cosmology and Ecology of Cyberspace_, [http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html][620], retrieved 2007-11-21  
* 
[Schmidhuber, Jürgen][621] (29 June 2006). "New Millennium AI and the Convergence of History". [arXiv][622]:[cs/0606081][623] [[cs.AI][624]].  
* 
[Singularity Institute for Artificial Intelligence][80] (2002), _Why Artificial Intelligence?_  [Archived][625] October 4, 2006 at the [Wayback Machine][626]

*  Singularity Institute for Artificial Intelligence (2004), [_3 Laws Unsafe_][627], [http://www.asimovlaws.com/][627], retrieved 2007-08-07  
*  Singularity Institute for Artificial Intelligence (2007), [_What is the Singularity?_][628], [http://www.singinst.org/overview/whatisthesingularity][628], retrieved 2008-01-04  
* 
[Smart, John][252] (September 2005), [_On Huebner Innovation_][562], Acceleration Studies Foundation, [http://accelerating.org/articles/huebnerinnovation.html][562], retrieved 2007-08-07  
* 
[Ulam, Stanislaw][629] (May 1958), "Tribute to John von Neumann", _Bulletin of the American Mathematical Society_ **64** (nr 3, part 2): 1–49  
* 
[Vinge, Vernor][9] (30–31 March 1993), ["The Coming Technological Singularity"][399], _Vision-21: Interdisciplinary Science & Engineering in the Era of CyberSpace, proceedings of a Symposium held at NASA Lewis Research Center_ ([NASA][143] Conference Publication CP-10129), [http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html][399], retrieved 2007-08-07 . See also [this HTML version][630], retrieved on 2009-03-29.
* 
[Warwick, Kevin][631] (2004), _March of The Machines_, University of Illinois Press, [ISBN][440] [978-0-252-07223-9][632]  

##  [[edit][633]] External links 

**Listen to this article** ([info/dl][634])

![Play sound][635]![][636]

This audio file was created from a revision of the "Technological singularity" article dated 2010-04-03, and does not reflect subsequent edits to the article. ([Audio help][637]) **[More spoken articles][638]**

[![Sound-icon.svg][639]][634]

###  [[edit][640]] Essays and articles 

* 
[Singularities and Nightmares: Extremes of Optimism and Pessimism About the Human Future][641] by [David Brin][334]

* 
[A Critical Discussion of Vinge’s Singularity Concept][642] by [Robin Hanson][131]

* 
[Is a singularity just around the corner][643] by Robin Hanson
* 
[Brief History of Intellectual Discussion of Accelerating Change][644] by [John Smart][252]

* 
[One Half of a Manifesto][645] by [Jaron Lanier][84] — a critique of "cybernetic totalism"
* 
[One Half of an Argument][646] — [Ray Kurzweil][10]'s response to Lanier
* 
[A discussion of Kurzweil, Turkel and Lanier][647] by Roger Berkowitz
* 
[The Singularity Is Always Near][648] by [Kevin Kelly][649]

* 
[The Maes-Garreau Point][650] by Kevin Kelly
* 
["The Singularity - A Philosophical Analysis"][496] by [David Chalmers][651]

* 
[2045: The Year Man Becomes Immortal][652], By Lev Grossman, time.com, Feb. 10, 2011.

###  [[edit][653]] Singularity AI projects 

* [The Singularity Institute for Artificial Intelligence][654]
* [The SSEC Machine Intelligence Project][655]
* [The Artificial General Intelligence Research Institute][656]

###  [[edit][657]] Fiction 

* 
[After Life][658] by Simon Funk uses a complex narrative structure to explore the relationships among uploaded minds in a technological singularity.
* 
[[Message Contains No Recognizable Symbols]][659] by [Bill Hibbard][202] is a story about a technological singularity subject to the constraint that natural human authors are unable to depict the actions and dialog of super-intelligent minds.
* Much of [Ben Goertzel's fiction][660] discusses a technological singularity.
* In "[The Turk][661]", an episode of the science fiction television series _[Terminator: The Sarah Connor Chronicles][662]_, John tells his mother about the Singularity, a point in time when machines will be able to build superior versions of themselves without the aid of humans.
* 
_[Accelerando][330]_ by [Charles Stross][329]

* 
_[Dresden Codak][352]_, a webcomic by Aaron Diaz, often contains plots relating to the singularity and [transhumanism][387], especially in the _[Hob][663]_ story arc
* 
[Endgame: Singularity][664] is an [open source][665] game where the player is AI, whose goal is to attain technological singularity/apotheosis.

###  [[edit][666]] Other links 

* [Report on _The Stanford Singularity Summit_][667]
* [2007 quotes, Singularity Summit, San Francisco][668]
* [Singularity Hub][669]
* [An IEEE report on the Singularity.][670]
* 
[March 2007 Congressional Report on the Singularity][671][Alternate Link][672]

* [The Global Transition][673]

|
|=

* [v][674]
* [t][675]
* [e][676]

[Technology][677]
|
|
|

* [Outline of technology][678]
* [Outline of applied science][679]

|
|
|=Fields|
|=Agriculture|

* [Agricultural engineering][680]
* [Aquaculture][681]
* [Fisheries science][682]
* [Food chemistry][683]
* [Food engineering][684]
* [Food microbiology][685]
* [Food technology][686]
* [GURT][687]
* [ICT in agriculture][688]
* [Nutrition][689]

|
|
|=[Biomedical][690]|

* [Bioinformatics][691]
* [Biological engineering][692]
* [Biomechatronics][693]
* [Biomedical engineering][694]
* [Biotechnology][695]
* [Cheminformatics][696]
* [Genetic engineering][157]
* [Healthcare science][697]
* [Medical research][698]
* [Medical technology][699]
* [Nanomedicine][700]
* [Neuroscience][701]
* [Pharmacology][702]
* [Reproductive technology][703]
* [Tissue engineering][704]

|
|
|=Buildings and construction|

* [Acoustical engineering][705]
* [Architectural engineering][706]
* [Building services engineering][707]
* [Civil engineering][708]
* [Construction engineering][709]
* [Domestic technology][710]
* [Facade engineering][711]
* [Fire protection engineering][712]
* [Safety engineering][713]
* [Sanitary engineering][714]
* [Structural engineering][715]

|
|
|=[Educational][716]|

* [Educational software][717]
* [Digital technologies in education][718]
* [ICT in education][719]
* [Impact][720]
* [Multimedia learning][721]
* [Virtual campus][722]
* [Virtual education][723]

|
|
|=[Energy][724]|

* [Nuclear engineering][725]
* [Nuclear technology][726]
* [Petroleum engineering][727]
* [Soft energy technology][728]

|
|
|=[Environmental][729]|

* [Clean technology][730]
* [Clean coal technology][731]
* [Ecological design][732]
* [Ecological engineering][733]
* [Ecotechnology][734]
* [Environmental engineering][735]
* [Environmental engineering science][736]
* [Green building][737]
* [Green nanotechnology][738]
* [Landscape engineering][739]
* [Renewable energy][740]
* [Sustainable design][741]
* [Sustainable engineering][742]

|
|
|=[Industrial][743]|

* [Automation][744]
* [Business informatics][745]
* [Engineering management][746]
* [Enterprise engineering][747]
* [Financial engineering][748]
* [Industrial biotechnology][749]
* [Industrial engineering][750]
* [Metallurgy][751]
* [Mining engineering][752]
* [Productivity improving technologies][753]
* [Research and development][754]

|
|
|=[IT and communications][755]|

* [Artificial intelligence][42]
* [Broadcast engineering][756]
* [Computer engineering][757]
* [Computer science][758]
* [Information technology][759]
* [Music technology][760]
* [Ontology engineering][761]
* [RF engineering][762]
* [Software engineering][763]
* [Telecommunications engineering][764]
* [Visual technology][765]

|
|
|=[Military][766]|

* [Army engineering maintenance][767]
* [Electronic warfare][768]
* [Military communications][769]
* [Military engineering][770]
* [Stealth technology][771]

|
|
|=[Transport][772]|

* [Aerospace engineering][773]
* [Automotive engineering][774]
* [Naval architecture][775]
* [Space technology][776]
* [Traffic engineering][777]
* [Transport engineering][778]

|
|
|=Other [applied sciences][779]
|

* [Cryogenics][780]
* [Electronics][781]
* [Engineering geology][782]
* [Engineering physics][783]
* [Hydraulics][784]
* [Materials science][785]
* [Microtechnology][786]
* [Nanotechnology][69]
* [Particle physics][787]

|
|
|=Other [engineering][788] fields|

* [Audio][789]
* [Biochemical][790]
* [Ceramic][791]
* [Chemical][792]
* [Control][793]
* [Electrical][794]
* [Electronic][795]
* [Entertainment][796]
* [Geotechnical][797]
* [Hydraulic][798]
* [Mechanical][799]
* [Mechatronics][800]
* [Optical][801]
* [Protein][802]
* [Quantum][803]
* [Robotics][804]
* [Systems][805]

|
|
|
|=[History][806]|

* [Prehistoric technology][807]
* [Neolithic Revolution][132]
* [Ancient technology][808]
* [Medieval technology][809]
* [Renaissance technology][810]
* 
[Industrial Revolution][185] ([Second][811]) 
* [Jet Age][812]
* [Information Age][813]

|
|
|=
[Theories][814] and concepts|

* [Appropriate technology][815]
* [Critique of technology][816]
* [Diffusion of innovations][817]
* [Disruptive technology][818]
* [Ephemeralization][819]
* [Ethics of technology][820]
* [High tech][821]
* [Hype cycle][822]
* [Inevitability thesis][823]
* [Low-technology][824]
* [Mature technology][825]
* [Philosophy of technology][826]
* [Posthumanism][827]
* [Strategy of Technology][828]
* [Technicism][829]
* [Techno-progressivism][830]
* [Technocapitalism][381]
* [Technocentrism][831]
* [Technocracy][832]
* [Technocriticism][833]
* [Technological change][834]
* [Technological convergence][835]
* [Technological determinism][382]
* [Technological escalation][836]
* [Technological evolution][383]
* [Technological innovation system][837]
* [Technological momentum][838]
* [Technological nationalism][839]
* [Technological rationality][840]
* [Technological revival][841]
* **Technological singularity**
* [Technological somnambulism][842]
* [Technological utopianism][843]
* 
[Technology life cycle][844]

* [Technology acceptance model][845]
* [Technology adoption lifecycle][846]

* [Technorealism][847]
* [Transhumanism][387]

|
|
|=Other|

* 
[Emerging technologies][848] ([List][366]) 
* [Fictional technology][849]
* [High-technology business districts][850]
* 
[Inventions][851] ([Timeline][852]) 
* [Kardashev scale][244]
* [List of technologies][853]
* [Science and technology by country][854]
* [Technology assessment][855]
* [Technology brokering][856]
* [Technology companies][857]
* 
[Technology education][858]

* [Technical universities and colleges][859]

* [Technology journalism][860]
* [Technology management][861]
* [Technology and society][862]
* [Technology transfer][863]

|
|
|

* 
![Wikipedia book][864]**[Book][865]**

* 
![Category][866]**[Category][867]**

* 
![][868]**[Commons][869]**

* 
![Portal][870]**[Portal][871]**

* 
![][872]**[Wikiquotes][873]**

|
|
|
|=

* [v][874]
* [t][875]
* [e][876]

[Emerging technologies][848]
|
|
|
[Technology][677]
|
|
|=Fields|
|=[Agriculture][877]|

* [Agricultural robot][878]
* [In vitro meat][879]
* [Genetically modified food][880]
* [Precision agriculture][881]
* [Vertical farming][882]

|
|
|=[Biomedical][690]|

* [Ampakine][883]
* [Cryonics][884]
* [Full genome sequencing][885]
* 
[Genetic engineering][157]

* [Gene therapy][886]

* [Personalized medicine][887]
* 
[Regenerative medicine][888]

* [Stem cell treatments][889]
* [Tissue engineering][704]

* [Robotic surgery][890]
* [Strategies for Engineered Negligible Senescence][891]
* [Suspended animation][892]
* 
[Synthetic biology][893]

* [Synthetic genomics][894]

* 
[Whole-body transplant][895]

* [Head transplant][896]
* [Isolated brain][897]

|
|
|=Displays|

* [Autostereoscopy][898]
* [Holographic display][899]
* [Next generation of display technology][900]
* 
[Screenless display][901]

* [Bionic contact lens][902]
* [Head-mounted display][903]
* [Head-up display][904]
* [Virtual retinal display][905]

* [Ultra High Definition Television][906]

|
|
|=Electronics|

* [Electronic nose][907]
* [Electronic textile][908]
* [Flexible electronics][909]
* [Memristor][910]
* [Spintronics][911]
* [Thermal copper pillar bump][912]

|
|
|=Energy|

* 
[Energy storage][913]

* [Beltway battery][914]
* [Compressed air energy storage][915]
* [Flywheel energy storage][916]
* [Grid energy storage][917]
* [Lithium air battery][918]
* [Molten salt battery][919]
* [Nanowire battery][920]
* [Silicon air battery][921]
* [Thermal energy storage][922]
* [Ultracapacitor][923]

* [Fusion power][924]
* [Molten salt reactor][925]
* 
[Renewable energy][740]

* [Airborne wind turbine][926]
* [Artificial photosynthesis][927]
* [Biofuels][928]
* [Concentrated solar power][929]
* [Home fuel cell][930]
* [Hydrogen economy][931]
* [Nantenna][932]
* [Solar roadway][933]
* [Space-based solar power][934]

* [Smart grid][935]
* [Wireless energy transfer][936]

|
|
|=[IT and communications][937]|

* 
[Artificial intelligence][42]

* [Applications of artificial intelligence][938]
* [Progress in artificial intelligence][939]
* [Machine translation][940]
* [Machine vision][941]
* [Semantic Web][942]
* [Speech recognition][174]

* [Atomtronics][943]
* [Cybermethodology][944]
* 
[Fourth-generation optical discs][945]

* [3D optical data storage][946]
* [Holographic data storage][947]

* [GPGPU][948]
* Memory 

* [CBRAM][949]
* [FRAM][950]
* [Millipede][951]
* [MRAM][952]
* [NRAM][953]
* [PRAM][954]
* [Racetrack memory][955]
* [RRAM][956]
* [SONOS][957]

* [Optical computing][958]
* [Quantum computing][959]
* [Quantum cryptography][960]
* [RFID][961]
* [Three-dimensional integrated circuit][962]

|
|
|=Manufacturing|

* 
[3D printing][963]

* [Contour Crafting][964]

* [Claytronics][965]
* [Molecular assembler][966]
* [Utility fog][967]

|
|
|=[Materials science][785]|

* [Graphene][968]
* [High-temperature superconductivity][969]
* [High-temperature superfluidity][970]
* 
[Metamaterials][971]

* [Metamaterial cloaking][972]

* [Multi-function structures][973]
* 
[Nanotechnology][69]

* [Carbon nanotubes][974]
* [Molecular nanotechnology][49]
* [Nanomaterials][975]

* [Programmable matter][976]
* [Quantum dots][977]

|
|
|=[Military][766]|

* [Antimatter weapon][978]
* 
[Directed-energy weapon][979]

* [Laser][980]
* [Maser][981]
* [Particle beam weapon][982]
* [Sonic weapon][983]

* 
[Electromagnetic weapon][984]

* [Coilgun][985]
* [Railgun][986]

* [Plasma weapon][987]
* [Pure fusion weapon][988]

|
|
|=[Neuroscience][701]|

* 
[Artificial brain][989]

* [Blue Brain Project][990]

* [Electroencephalography][991]
* 
[Mind uploading][160]

* [Brain-reading][992]
* [Neuroinformatics][993]

* 
[Neuroprosthetics][994]

* [Bionic eye][995]
* [Brain implant][996]
* [Exocortex][997]
* [Retinal implant][998]

|
|
|=[Robotics][804]|

* [Nanorobotics][999]
* [Powered exoskeleton][1000]
* [Self-reconfiguring modular robot][1001]
* [Swarm robotics][1002]

|
|
|=Transport|

* [Adaptive Compliant Wing][1003]
* 
[Alternative fuel vehicle][1004]

* [Hydrogen vehicle][1005]

* [Backpack helicopter][1006]
* [Driverless car][1007]
* [Flying car][1008]
* [Ground effect train][1009]
* [Jet pack][1010]
* [Interstellar travel][1011]
* [Laser propulsion][1012]
* [Maglev train][1013]
* 
[Non-rocket spacelaunch][1014]

* [Mass driver][1015]
* [Orbital ring][1016]
* [Skyhook][1017]
* [Space elevator][1018]
* [Space fountain][1019]
* [Space tether][1020]

* 
[Personal rapid transit][1021]

* [ETT][1022]

* [Pulse detonation engine][1023]
* [Nuclear pulse propulsion][1024]
* [Scramjet][1025]
* [Solar sail][1026]
* [Spaceplane][1027]
* [Supersonic transport][1028]
* [Tweel][1029]
* [Vactrain][1030]

|
|
|=Other|

* [Anti-gravity][1031]
* [Arcology][1032]
* [Cloak of invisibility][1033]
* [Digital scent technology][1034]
* [Domed city][1035]
* 
[Force field][1036]

* [Plasma window][1037]

* [Immersive virtual reality][1038]
* [Magnetic refrigeration][1039]
* [Phased-array optics][1040]
* 
[Quantum technology][803]

* [Quantum teleportation][1041]

|
|
|
|=Other|

* [Differential technological development][1042]
* [Ephemeralization][819]
* [Exploratory engineering][1043]
* [Fictional technology][849]
* [Technological convergence][835]
* [Technological evolution][383]
* 
[Technology forecasting][1044]

* [Accelerating change][110]
* [Moore's law][36]
* [Timeline of the future in forecasts][1045]
* **Technological singularity**
* [Technology scouting][1046]

* [Technology readiness level][1047]
* [Technology roadmap][1048]
* [Transhumanism][387]
* [Virtusphere][1049]

|
|
|

* 
![Category][866]**[Category][1050]**

* 
![List-Class article][1051]**[List][366]**

|
|

Retrieved from "[http://en.wikipedia.org/w/index.php?title=Technological_singularity&oldid=499252190][1052]"

[Categories][1053]: 

* [Evolution][1054]
* [Sociocultural evolution][1055]
* [Theories of history][1056]
* [Futurology][1057]
* [Singularitarianism][1058]
* [Philosophy of artificial intelligence][1059]
* [Eschatology][1060]

 Hidden categories: 

* [All articles with dead external links][1061]
* [Articles with dead external links from July 2011][1062]
* [All articles with unsourced statements][1063]
* [Articles with unsourced statements from October 2011][1064]
* [Articles with unsourced statements from August 2010][1065]
* [Wikipedia articles needing clarification from October 2009][1066]
* [Articles with unsourced statements from November 2010][1067]
* [Articles with unsourced statements from March 2010][1068]
* [Articles with dead external links from July 2009][1069]
* [Wikipedia external links cleanup from March 2011][1070]
* [Wikipedia spam cleanup from March 2011][1071]
* [Spoken articles][1072]
* [Articles with hAudio microformats][1073]

----

This page was forked with permission from [http://en.wikipedia.org/wiki/Technological_singularity][1074]

----

[][1075]

[1]: 
[2]: #mw-head
[3]: #p-search
[4]: http://en.wikipedia.org/wiki/Superintelligence
[5]: #cite_note-0
[6]: http://en.wikipedia.org/wiki/Event_horizon
[7]: #cite_note-Singularity.2C_Intelligence_Explosion_2010-1
[8]: #cite_note-2
[9]: http://en.wikipedia.org/wiki/Vernor_Vinge
[10]: http://en.wikipedia.org/wiki/Ray_Kurzweil
[11]: #Basic_concepts
[12]: #History_of_the_idea
[13]: #Intelligence_explosion
[14]: #Speed_improvements
[15]: #Intelligence_improvements
[16]: #Impact
[17]: #Existential_risk
[18]: #Implications_for_human_society
[19]: #Accelerating_change
[20]: #Criticism
[21]: #Criticism_of_the_accelerating_returns_argument
[22]: #In_popular_culture
[23]: #See_also
[24]: #Notes
[25]: #References
[26]: #External_links
[27]: #Essays_and_articles
[28]: #Singularity_AI_projects
[29]: #Fiction
[30]: #Other_links
[31]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=1
[32]: //upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTMooresLawai.jpg/225px-PPTMooresLawai.jpg
[33]: http://en.wikipedia.org/wiki/File:PPTMooresLawai.jpg
[34]: //bits.wikimedia.org/static-1.20wmf5/skins/common/images/magnify-clip.png
[35]: http://en.wikipedia.org/wiki/Paradigm_shift
[36]: http://en.wikipedia.org/wiki/Moore%27s_law
[37]: http://en.wikipedia.org/wiki/Integrated_circuits
[38]: http://en.wikipedia.org/wiki/Transistor
[39]: http://en.wikipedia.org/wiki/Vacuum_tube
[40]: http://en.wikipedia.org/wiki/Relay
[41]: http://en.wikipedia.org/wiki/Electromechanics
[42]: http://en.wikipedia.org/wiki/Artificial_intelligence
[43]: #cite_note-vinge1993-3
[44]: #cite_note-singularity-4
[45]: #cite_note-singinst.org-5
[46]: http://en.wikipedia.org/wiki/Physics
[47]: http://en.wikipedia.org/wiki/Gravitational_singularity
[48]: http://en.wikipedia.org/wiki/Black_hole
[49]: http://en.wikipedia.org/wiki/Molecular_nanotechnology
[50]: #cite_note-hplusmagazine-6
[51]: #cite_note-yudkowsky.net-7
[52]: #cite_note-agi-conf-8
[53]: http://en.wikipedia.org/wiki/Moore%27s_Law
[54]: #cite_note-kurzweilai.net-9
[55]: http://en.wikipedia.org/wiki/I._J._Good
[56]: #cite_note-stat-10
[57]: http://en.wikipedia.org/wiki/Paul_R._Ehrlich
[58]: #cite_note-Paul_Ehrlich_June_2008-11
[59]: #cite_note-businessweek-12
[60]: http://en.wikipedia.org/wiki/Intelligence_amplification
[61]: http://en.wikipedia.org/wiki/Seed_AI
[62]: #cite_note-ultraintelligent-13
[63]: #cite_note-acceleratingfuture-14
[64]: #cite_note-ultraintelligent1-15
[65]: http://en.wikipedia.org/wiki/Hans_Moravec
[66]: http://en.wikipedia.org/wiki/Integrated_circuit
[67]: http://en.wikipedia.org/wiki/Law_of_accelerating_returns
[68]: #cite_note-google-16
[69]: http://en.wikipedia.org/wiki/Nanotechnology
[70]: #cite_note-singularity2-17
[71]: #cite_note-singularity3-18
[72]: #cite_note-transformation-19
[73]: #cite_note-positive-and-negative-20
[74]: #cite_note-theuncertainfuture-21
[75]: http://en.wikipedia.org/wiki/Existential_risk
[76]: #cite_note-catastrophic-22
[77]: #cite_note-nickbostrom-23
[78]: http://en.wikipedia.org/wiki/Artificial_general_intelligence
[79]: http://en.wikipedia.org/wiki/Friendly_AI
[80]: http://en.wikipedia.org/wiki/Singularity_Institute_for_Artificial_Intelligence
[81]: http://en.wikipedia.org/wiki/Future_of_Humanity_Institute
[82]: http://en.wikipedia.org/wiki/Jeff_Hawkins
[83]: http://en.wikipedia.org/wiki/John_Henry_Holland
[84]: http://en.wikipedia.org/wiki/Jaron_Lanier
[85]: http://en.wikipedia.org/wiki/Gordon_Moore
[86]: #cite_note-spectrum.ieee.org-24
[87]: #cite_note-ieee-25
[88]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=2
[89]: http://en.wikipedia.org/wiki/Friedrich_Engels
[90]: #cite_note-The_Expounder_of_Primitive_Christianity-26
[91]: http://en.wikipedia.org/wiki/Mechanical_calculator
[92]: http://en.wikipedia.org/wiki/Alan_Turing
[93]: #cite_note-oxfordjournals-27
[94]: http://en.wikipedia.org/wiki/Samuel_Butler_(novelist)
[95]: http://en.wikipedia.org/wiki/Erewhon
[96]: http://en.wikipedia.org/wiki/Stanis%C5%82aw_Marcin_Ulam
[97]: #cite_note-mathematical-28
[98]: http://en.wikipedia.org/wiki/John_von_Neumann
[99]: http://en.wikipedia.org/wiki/Recursion
[100]: http://en.wikipedia.org/wiki/Omni_(magazine)
[101]: #cite_note-google4-29
[102]: #cite_note-technological-30
[103]: http://en.wikipedia.org/wiki/Samuel_R._Delany
[104]: http://en.wikipedia.org/wiki/Stars_in_My_Pocket_Like_Grains_of_Sand
[105]: http://en.wikipedia.org/wiki/Ray_Solomonoff
[106]: #cite_note-std-31
[107]: http://en.wikipedia.org/wiki/Future_shock
[108]: http://en.wikipedia.org/wiki/Marooned_in_Realtime
[109]: http://en.wikipedia.org/wiki/A_Fire_Upon_the_Deep
[110]: http://en.wikipedia.org/wiki/Accelerating_change
[111]: http://en.wikipedia.org/wiki/Transcendence_(philosophy)
[112]: http://en.wikipedia.org/wiki/Omnipotent
[113]: #cite_note-When_will_computer_hardware_match_the_human_brain.3F-32
[114]: #cite_note-The_Age_of_Robots-33
[115]: #cite_note-Robot_Predictions_Evolution-34
[116]: http://en.wikipedia.org/wiki/Robot_intelligence
[117]: #cite_note-google5-35
[118]: #cite_note-36
[119]: http://en.wikipedia.org/wiki/Feedback_loop
[120]: http://en.wikipedia.org/wiki/Damien_Broderick
[121]: http://en.wikipedia.org/wiki/The_Spike_(1997)
[122]: http://en.wikipedia.org/wiki/Bill_Joy
[123]: http://en.wikipedia.org/wiki/Sun_Microsystems
[124]: #cite_note-JoyFuture-37
[125]: http://en.wikipedia.org/wiki/The_Singularity_is_Near
[126]: http://en.wikipedia.org/wiki/The_Daily_Show_with_Jon_Stewart
[127]: #cite_note-episode-38
[128]: http://en.wikipedia.org/wiki/Barry_Ptolemy
[129]: http://en.wikipedia.org/wiki/Transcendent_Man_(film)
[130]: http://en.wikipedia.org/wiki/Eliezer_Yudkowsky
[131]: http://en.wikipedia.org/wiki/Robin_Hanson
[132]: http://en.wikipedia.org/wiki/Neolithic_Revolution
[133]: http://en.wikipedia.org/wiki/Industrial_revolution
[134]: http://en.wikipedia.org/wiki/Economic_growth
[135]: #cite_note-Hanson-39
[136]: http://en.wikipedia.org/wiki/X-Prize
[137]: http://en.wikipedia.org/wiki/Peter_Diamandis
[138]: http://en.wikipedia.org/wiki/Singularity_University
[139]: #cite_note-singularityu-40
[140]: http://en.wikipedia.org/wiki/Google
[141]: http://en.wikipedia.org/wiki/Autodesk
[142]: http://en.wikipedia.org/wiki/EPlanet_Ventures
[143]: http://en.wikipedia.org/wiki/NASA
[144]: http://en.wikipedia.org/wiki/NASA_Ames_Research_Center
[145]: http://en.wikipedia.org/wiki/Mountain_View,_California
[146]: http://en.wikipedia.org/wiki/California
[147]: http://en.wikipedia.org/wiki/Wikipedia:Citation_needed
[148]: http://en.wikipedia.org/wiki/Aubrey_de_Grey
[149]: #cite_note-sens-41
[150]: http://en.wikipedia.org/wiki/Life_expectancy
[151]: #cite_note-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality-42
[152]: #cite_note-time-43
[153]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=3
[154]: #CITEREFGood1965
[155]: http://en.wikipedia.org/wiki/Transhuman
[156]: http://en.wikipedia.org/wiki/Bioengineering
[157]: http://en.wikipedia.org/wiki/Genetic_engineering
[158]: http://en.wikipedia.org/wiki/Nootropic
[159]: http://en.wikipedia.org/wiki/Brain-computer_interface
[160]: http://en.wikipedia.org/wiki/Mind_uploading
[161]: #CITEREFHanson1998
[162]: #cite_note-david_chalmers_singularity_lecture_resources_available-44
[163]: http://en.wikipedia.org/wiki/Quantum_Computing
[164]: #cite_note-consc.net-45
[165]: http://en.wikipedia.org/wiki/Moore%E2%80%99s_Law
[166]: #cite_note-itrs-46
[167]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=4
[168]: #cite_note-arstechnica-47
[169]: #cite_note-singularity6-48
[170]: #CITEREFHawkins2008
[171]: http://en.wikipedia.org/wiki/Silicon
[172]: http://en.wikipedia.org/wiki/Neuron
[173]: #CITEREFBerglas2008
[174]: http://en.wikipedia.org/wiki/Speech_recognition
[175]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=5
[176]: http://en.wikipedia.org/wiki/AI_box
[177]: #cite_note-yudkowsky-49
[178]: #cite_note-selfawaresystems-50
[179]: #cite_note-kurzweilai-51
[180]: #cite_note-selfawaresystems.com-52
[181]: #cite_note-ReferenceB-53
[182]: #cite_note-nickbostrom7-54
[183]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=6
[184]: http://en.wikipedia.org/wiki/Paleolithic
[185]: http://en.wikipedia.org/wiki/Industrial_Revolution
[186]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=7
[187]: http://en.wikipedia.org/wiki/Nick_Bostrom
[188]: #cite_note-nickbostrom8-55
[189]: #cite_note-singinst-56
[190]: #cite_note-singinst9-57
[191]: http://en.wikipedia.org/wiki/Anders_Sandberg
[192]: #cite_note-aleph-58
[193]: http://en.wikipedia.org/wiki/Hugo_de_Garis
[194]: #cite_note-selfawaresystems10-59
[195]: #cite_note-forbes-60
[196]: #CITEREFBostrom2002
[197]: http://en.wikipedia.org/wiki/Protein_folding
[198]: #cite_note-berglas-61
[199]: #cite_note-philosophical-62
[200]: http://en.wikipedia.org/wiki/Friendly_artificial_intelligence
[201]: #cite_note-singinst12-63
[202]: http://en.wikipedia.org/wiki/Bill_Hibbard
[203]: http://en.wikipedia.org/wiki/Super-Intelligent_Machines
[204]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=8
[205]: http://en.wikipedia.org/wiki/Monterey_Bay
[206]: http://en.wikipedia.org/wiki/Computer_viruses
[207]: #cite_note-nytimes_july09-64
[208]: #cite_note-palmer-65
[209]: http://en.wikipedia.org/wiki/United_States_Navy
[210]: #cite_note-dailytech-66
[211]: #cite_note-engadget-67
[212]: http://en.wikipedia.org/wiki/Association_for_the_Advancement_of_Artificial_Intelligence
[213]: #cite_note-microsoft-68
[214]: http://en.wikipedia.org/wiki/Language_Acquisition_Device_(computer)
[215]: http://en.wikipedia.org/wiki/Singularitarianism
[216]: http://en.wikipedia.org/wiki/Foresight_Institute
[217]: #cite_note-asimovlaws-69
[218]: http://en.wikipedia.org/wiki/Isaac_Asimov
[219]: http://en.wikipedia.org/wiki/Three_Laws_of_Robotics
[220]: http://en.wikipedia.org/wiki/2004_in_film
[221]: http://en.wikipedia.org/wiki/I,_Robot_(film)
[222]: http://en.wikipedia.org/wiki/Robot_series_(Asimov)
[223]: http://en.wikipedia.org/wiki/Zeroth_Law
[224]: #CITEREFSingularity_Institute_for_Artificial_Intelligence2004
[225]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=9
[226]: //upload.wikimedia.org/wikipedia/commons/thumb/4/45/ParadigmShiftsFrr15Events.svg/195px-ParadigmShiftsFrr15Events.svg.png
[227]: http://en.wikipedia.org/wiki/File:ParadigmShiftsFrr15Events.svg
[228]: http://en.wikipedia.org/wiki/Logarithmic_scale
[229]: http://en.wikipedia.org/wiki/Human_history
[230]: http://en.wikipedia.org/wiki/Exponential_growth
[231]: http://en.wikipedia.org/wiki/Wikipedia:Please_clarify
[232]: http://en.wikipedia.org/wiki/Carl_Sagan
[233]: http://en.wikipedia.org/wiki/Paul_D._Boyer
[234]: http://en.wikipedia.org/wiki/Encyclop%C3%A6dia_Britannica
[235]: http://en.wikipedia.org/wiki/American_Museum_of_Natural_History
[236]: http://en.wikipedia.org/wiki/University_of_Arizona
[237]: #CITEREFUlam1958
[238]: #CITEREFHawkins1983
[239]: #CITEREFKurzweil2001
[240]: http://en.wikipedia.org/wiki/Predictions_made_by_Raymond_Kurzweil#2045:_The_Singularity
[241]: #CITEREFKurzweil2005
[242]: http://en.wikipedia.org/wiki/Dan_Simmons
[243]: http://en.wikipedia.org/wiki/Hyperion_(Simmons_novel)
[244]: http://en.wikipedia.org/wiki/Kardashev_scale
[245]: http://en.wikipedia.org/wiki/Planetary_system
[246]: http://en.wikipedia.org/wiki/Galaxy
[247]: #cite_note-civilization-70
[248]: http://en.wikipedia.org/wiki/Wired_(magazine)
[249]: http://en.wikipedia.org/wiki/Why_the_future_doesn%27t_need_us
[250]: #CITEREFJoy2000
[251]: http://en.wikipedia.org/wiki/Acceleration_Studies_Foundation
[252]: http://en.wikipedia.org/wiki/John_Smart_(futurist)
[253]: #CITEREFAcceleration_Studies_Foundation2007
[254]: http://www.accelerationwatch.com/
[255]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=10
[256]: http://en.wikipedia.org/wiki/Steven_Pinker
[257]: #cite_note-dreyfus-71
[258]: #cite_note-thelightsinthetunnel-72
[259]: #cite_note-nytimes-73
[260]: http://en.wikipedia.org/wiki/Jared_Diamond
[261]: http://en.wikipedia.org/wiki/Collapse:_How_Societies_Choose_to_Fail_or_Succeed
[262]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=11
[263]: http://en.wikipedia.org/wiki/Theodore_Modis
[264]: #cite_note-google13-74
[265]: #cite_note-Singularity_Myth-75
[266]: http://en.wikipedia.org/wiki/Jonathan_Huebner
[267]: #cite_note-technological14-76
[268]: #cite_note-accelerating-77
[269]: http://en.wikipedia.org/wiki/Clock_rate
[270]: #cite_note-cnet-78
[271]: http://en.wikipedia.org/wiki/World_population
[272]: http://en.wikipedia.org/wiki/Gross_domestic_product
[273]: http://en.wikipedia.org/wiki/Andrey_Korotayev
[274]: http://en.wikipedia.org/wiki/Hyperbolic_growth
[275]: #cite_note-cliodynamics-79
[276]: #cite_note-80
[277]: http://en.wikipedia.org/wiki/William_Nordhaus
[278]: #CITEREFSchmidhuber2006
[279]: http://en.wikipedia.org/wiki/British_Interplanetary_Society
[280]: http://en.wikipedia.org/wiki/Wait_Calculation
[281]: #cite_note-interstellar-81
[282]: http://en.wikipedia.org/wiki/Quantum_mechanics
[283]: http://en.wikipedia.org/wiki/Richard_Feynman
[284]: http://en.wikipedia.org/wiki/Hans_Bethe
[285]: http://en.wikipedia.org/wiki/Quantum_entanglement
[286]: http://en.wikipedia.org/wiki/Joseph_Tainter
[287]: #cite_note-university-82
[288]: http://en.wikipedia.org/wiki/Thomas_Homer_Dixon
[289]: http://en.wikipedia.org/wiki/The_Upside_of_Down
[290]: http://en.wikipedia.org/wiki/PZ_Myers
[291]: #cite_note-PZMyers-83
[292]: http://en.wikipedia.org/wiki/The_Economist
[293]: #cite_note-moreblades-84
[294]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=12
[295]: http://en.wikipedia.org/wiki/List_of_fictional_computers
[296]: http://en.wikipedia.org/wiki/The_Evitable_Conflict
[297]: http://en.wikipedia.org/wiki/I,_Robot
[298]: http://en.wikipedia.org/wiki/Bootstrapping
[299]: http://en.wikipedia.org/wiki/Susan_Calvin
[300]: http://en.wikipedia.org/wiki/James_P._Hogan_(writer)
[301]: http://en.wikipedia.org/wiki/Greg_Bear
[302]: http://en.wikipedia.org/wiki/Blood_Music_(novel)
[303]: http://en.wikipedia.org/wiki/William_Gibson
[304]: http://en.wikipedia.org/wiki/Neuromancer
[305]: http://en.wikipedia.org/wiki/The_Metamorphosis_of_Prime_Intellect
[306]: http://en.wikipedia.org/wiki/Bruce_Sterling
[307]: http://en.wikipedia.org/wiki/Alternate_history
[308]: http://en.wikipedia.org/wiki/Steampunk
[309]: http://en.wikipedia.org/wiki/The_Difference_Engine
[310]: http://en.wikipedia.org/wiki/Harlan_Ellison
[311]: http://en.wikipedia.org/wiki/I_Have_No_Mouth,_and_I_Must_Scream
[312]: http://en.wikipedia.org/wiki/William_Thomas_Quick
[313]: http://en.wikipedia.org/wiki/Neal_Asher
[314]: http://en.wikipedia.org/wiki/Gridlinked
[315]: http://en.wikipedia.org/wiki/Polity_Agent
[316]: http://en.wikipedia.org/wiki/Ken_MacLeod
[317]: http://en.wikipedia.org/wiki/Rapture
[318]: http://en.wikipedia.org/wiki/Colossus:_The_Forbin_Project
[319]: http://en.wikipedia.org/wiki/Terminator_(franchise)
[320]: http://en.wikipedia.org/wiki/The_Matrix_(series)
[321]: http://en.wikipedia.org/wiki/Battlestar_Galactica_(2004_TV_series)
[322]: http://en.wikipedia.org/wiki/The_Last_Question
[323]: http://en.wikipedia.org/wiki/Strong_artificial_intelligence
[324]: http://en.wikipedia.org/wiki/Post-human
[325]: http://en.wikipedia.org/wiki/Heat_death_of_the_universe
[326]: http://en.wikipedia.org/wiki/St._Edward%27s_University
[327]: http://en.wikipedia.org/wiki/Eamonn_Healy
[328]: http://en.wikipedia.org/wiki/Waking_Life
[329]: http://en.wikipedia.org/wiki/Charles_Stross
[330]: http://en.wikipedia.org/wiki/Accelerando_(book)
[331]: http://en.wikipedia.org/wiki/Karl_Schroeder
[332]: http://en.wikipedia.org/wiki/Greg_Egan
[333]: http://en.wikipedia.org/wiki/Rudy_Rucker
[334]: http://en.wikipedia.org/wiki/David_Brin
[335]: http://en.wikipedia.org/wiki/Iain_M._Banks
[336]: http://en.wikipedia.org/wiki/Neal_Stephenson
[337]: http://en.wikipedia.org/wiki/Tony_Ballantyne
[338]: http://en.wikipedia.org/wiki/Fredric_Brown
[339]: http://en.wikipedia.org/wiki/Jacek_Dukaj
[340]: http://en.wikipedia.org/wiki/Stanislav_Lem
[341]: http://en.wikipedia.org/wiki/Nagaru_Tanigawa
[342]: http://en.wikipedia.org/wiki/Douglas_Adams
[343]: http://en.wikipedia.org/wiki/Michael_Crichton
[344]: http://en.wikipedia.org/wiki/Ian_McDonald_(author)
[345]: http://en.wikipedia.org/wiki/Plug_%26_Pray
[346]: http://en.wikipedia.org/wiki/Joseph_Weizenbaum
[347]: #cite_note-plugandpray-film-85
[348]: #cite_note-cnet15-86
[349]: http://en.wikipedia.org/wiki/Cornell
[350]: #cite_note-wired-87
[351]: #cite_note-cornell-88
[352]: http://en.wikipedia.org/wiki/Dresden_Codak
[353]: http://en.wikipedia.org/wiki/The_Big_Bang_Theory
[354]: http://en.wikipedia.org/wiki/Industrial_Music
[355]: http://en.wikipedia.org/wiki/Doctor_Steel
[356]: http://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies
[357]: #cite_note-IEET_interview-89
[358]: #cite_note-Paranoia_magazine-90
[359]: #cite_note-Paranoia_magazine_clipping-91
[360]: http://sola-mi.com
[361]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=13
[362]: http://en.wikipedia.org/wiki/Democratic_Transhumanism
[363]: http://en.wikipedia.org/wiki/Development_criticism
[364]: http://en.wikipedia.org/wiki/Doomsday_argument
[365]: http://en.wikipedia.org/wiki/Eschatology#Empirical_and_Rationalist_based
[366]: http://en.wikipedia.org/wiki/List_of_emerging_technologies
[367]: http://en.wikipedia.org/wiki/Logarithmic_timeline
[368]: http://en.wikipedia.org/wiki/Detailed_logarithmic_timeline
[369]: http://en.wikipedia.org/wiki/Molecular_engineering
[370]: http://en.wikipedia.org/wiki/Novelty_theory#Timewave_zero_and_the_I_Ching
[371]: http://en.wikipedia.org/wiki/Omega_Point
[372]: http://en.wikipedia.org/wiki/Positive_feedback
[373]: //upload.wikimedia.org/wikipedia/commons/thumb/7/70/Sustainable_development.svg/32px-Sustainable_development.svg.png
[374]: http://en.wikipedia.org/wiki/File:Sustainable_development.svg
[375]: http://en.wikipedia.org/wiki/Portal:Sustainable_development
[376]: http://en.wikipedia.org/wiki/Post_Scarcity
[377]: http://en.wikipedia.org/wiki/Predictive_medicine
[378]: http://en.wikipedia.org/wiki/Sentience_quotient
[379]: http://en.wikipedia.org/wiki/Simulated_reality
[380]: http://en.wikipedia.org/wiki/The_Singularity_Is_Near
[381]: http://en.wikipedia.org/wiki/Technocapitalism
[382]: http://en.wikipedia.org/wiki/Technological_determinism
[383]: http://en.wikipedia.org/wiki/Technological_evolution
[384]: http://en.wikipedia.org/wiki/Techno-utopianism
[385]: http://en.wikipedia.org/wiki/Tipping_point
[386]: http://en.wikipedia.org/wiki/Transcendent_Man
[387]: http://en.wikipedia.org/wiki/Transhumanism
[388]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=14
[389]: #cite_ref-0
[390]: http://www.nickbostrom.com/views/superintelligence.pdf
[391]: #cite_ref-Singularity.2C_Intelligence_Explosion_2010_1-0
[392]: #cite_ref-Singularity.2C_Intelligence_Explosion_2010_1-1
[393]: http://singinst.org/blog/2010/04/08/david-chalmers-on-singularity-intelligence-explosion/
[394]: #cite_ref-2
[395]: http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/
[396]: #cite_ref-vinge1993_3-0
[397]: #cite_ref-vinge1993_3-1
[398]: #cite_ref-vinge1993_3-2
[399]: http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html
[400]: #cite_ref-singularity_4-0
[401]: #cite_ref-singinst.org_5-0
[402]: #cite_ref-singinst.org_5-1
[403]: #cite_ref-singinst.org_5-2
[404]: #cite_ref-singinst.org_5-3
[405]: http://singinst.org/overview/whatisthesingularity
[406]: #cite_ref-hplusmagazine_6-0
[407]: http://www.hplusmagazine.com/articles/nano/singularity-nanotech-or-ai
[408]: #cite_ref-yudkowsky.net_7-0
[409]: #cite_ref-yudkowsky.net_7-1
[410]: #cite_ref-yudkowsky.net_7-2
[411]: http://yudkowsky.net/singularity/schools
[412]: #cite_ref-agi-conf_8-0
[413]: http://agi-conf.org/2010/wp-content/uploads/2009/06/agi10singmodels2.pdf
[414]: #cite_ref-kurzweilai.net_9-0
[415]: #cite_ref-kurzweilai.net_9-1
[416]: http://www.kurzweilai.net/max-more-and-ray-kurzweil-on-the-singularity-2
[417]: #cite_ref-stat_10-0
[418]: http://www.stat.vt.edu/tech_reports/2005/GoodTechReport.pdf
[419]: #cite_ref-Paul_Ehrlich_June_2008_11-0
[420]: http://www.longnow.org/seminars/02008/jun/27/dominant-animal-human-evolution-and-environment/
[421]: #cite_ref-businessweek_12-0
[422]: http://www.businessweek.com/1999/99_35/b3644021.htm
[423]: #cite_ref-ultraintelligent_13-0
[424]: #cite_ref-acceleratingfuture_14-0
[425]: http://www.acceleratingfuture.com/people-blog/2007/the-human-importance-of-the-intelligence-explosion/
[426]: #cite_ref-ultraintelligent1_15-0
[427]: #cite_ref-google_16-0
[428]: http://books.google.com/books?id=ldAGcyh0bkUC&lpg=PP1&pg=PA630#v=onepage&q&f=false
[429]: http://books.google.com/books?id=ldAGcyh0bkUC&lpg=PP1&pg=PA632#v=onepage&q&f=false
[430]: #cite_ref-singularity2_17-0
[431]: #cite_ref-singularity3_18-0
[432]: #cite_ref-transformation_19-0
[433]: #cite_ref-positive-and-negative_20-0
[434]: #cite_ref-positive-and-negative_20-1
[435]: #cite_ref-positive-and-negative_20-2
[436]: #cite_ref-positive-and-negative_20-3
[437]: http://singinst.org/AIRisk.pdf
[438]: http://en.wikipedia.org/wiki/Bibcode
[439]: http://adsabs.harvard.edu/abs/2008gcr..book..303Y
[440]: http://en.wikipedia.org/wiki/International_Standard_Book_Number
[441]: http://en.wikipedia.org/wiki/Special:BookSources/978-0-19-857050-9
[442]: #cite_ref-theuncertainfuture_21-0
[443]: http://www.theuncertainfuture.com/
[444]: #cite_ref-catastrophic_22-0
[445]: http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/3854/global-catastrophic-risks-report.pdf
[446]: #cite_ref-nickbostrom_23-0
[447]: http://www.nickbostrom.com/existential/risks.html
[448]: #cite_ref-spectrum.ieee.org_24-0
[449]: #cite_ref-spectrum.ieee.org_24-1
[450]: http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity
[451]: #cite_ref-ieee_25-0
[452]: http://spectrum.ieee.org/computing/hardware/whos-who-in-the-singularity
[453]: #cite_ref-The_Expounder_of_Primitive_Christianity_26-0
[454]: http://books.google.com/?id=ZM_hAAAAMAAJ&dq=%22Primitive%20Expounder%22%20thornton%201847&pg=PA281#v=onepage&q=thinking%20machine&f=false
[455]: #cite_ref-oxfordjournals_27-0
[456]: http://en.wikipedia.org/wiki/Digital_object_identifier
[457]: http://dx.doi.org/10.1093%2Fphilmat%2F4.3.256
[458]: http://philmat.oxfordjournals.org/content/4/3/256.full.pdf
[459]: #cite_ref-mathematical_28-0
[460]: #cite_ref-google4_29-0
[461]: http://books.google.com/books?id=VbBRsv1lxsUC&lpg=PP1&pg=PA88#v=onepage&q&f=false
[462]: #cite_ref-technological_30-0
[463]: #cite_ref-std_31-0
[464]: http://world.std.com/~rjs/timesc.pdf
[465]: #cite_ref-When_will_computer_hardware_match_the_human_brain.3F_32-0
[466]: http://www.transhumanist.com/volume1/moravec.htm
[467]: #cite_ref-The_Age_of_Robots_33-0
[468]: http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html
[469]: #cite_ref-Robot_Predictions_Evolution_34-0
[470]: http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2004/Predictions.html
[471]: #cite_ref-google5_35-0
[472]: http://books.google.com/books?id=VbBRsv1lxsUC&lpg=PP1&pg=PA89#v=onepage&q&f=false
[473]: #cite_ref-36
[474]: #cite_ref-JoyFuture_37-0
[475]: http://www.wired.com/wired/archive/8.04/joy.html
[476]: http://en.wikipedia.org/wiki/Special:BookSources/0-670-03249-2
[477]: #cite_ref-episode_38-0
[478]: http://www.imdb.com/title/tt847969/
[479]: http://en.wikipedia.org/wiki/Internet_Movie_Database
[480]: #cite_ref-Hanson_39-0
[481]: #cite_ref-Hanson_39-1
[482]: http://www.spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity
[483]: http://hanson.gmu.edu/longgrow.pdf
[484]: #cite_ref-singularityu_40-0
[485]: http://singularityu.org/about/
[486]: #cite_ref-sens_41-0
[487]: http://www.sens.org/files/sens/FHTI07-deGrey.pdf
[488]: http://en.wikipedia.org/wiki/Wikipedia:Link_rot
[489]: #cite_ref-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality_42-0
[490]: http://en.wikipedia.org/wiki/Special:BookSources/978-0-19-539302-6
[491]: #cite_ref-time_43-0
[492]: http://www.time.com/time/magazine/article/0,9171,2048299,00.html
[493]: #cite_ref-david_chalmers_singularity_lecture_resources_available_44-0
[494]: http://www.fhi.ox.ac.uk/news/2010/david_chalmers_singularity_lecture_resources_available
[495]: #cite_ref-consc.net_45-0
[496]: http://consc.net/papers/singularity.pdf
[497]: #cite_ref-itrs_46-0
[498]: http://www.itrs.net/Links/2007ITRS/ExecSum2007.pdf
[499]: #cite_ref-arstechnica_47-0
[500]: http://arstechnica.com/apple/reviews/2009/08/mac-os-x-10-6.ars/8
[501]: #cite_ref-singularity6_48-0
[502]: #cite_ref-yudkowsky_49-0
[503]: http://yudkowsky.net/singularity/power
[504]: #cite_ref-selfawaresystems_50-0
[505]: http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/
[506]: #cite_ref-kurzweilai_51-0
[507]: http://www.kurzweilai.net/artificial-general-intelligence-now-is-the-time
[508]: #cite_ref-selfawaresystems.com_52-0
[509]: #cite_ref-selfawaresystems.com_52-1
[510]: http://selfawaresystems.com/2007/10/05/paper-on-the-nature-of-self-improving-artificial-intelligence/
[511]: #cite_ref-ReferenceB_53-0
[512]: #cite_ref-ReferenceB_53-1
[513]: http://singinst.org/riskintro/index.html
[514]: #cite_ref-nickbostrom7_54-0
[515]: #cite_ref-nickbostrom7_54-1
[516]: http://www.nickbostrom.com/fut/evolution.html
[517]: #cite_ref-nickbostrom8_55-0
[518]: http://www.nickbostrom.com/ethics/ai.html
[519]: #cite_ref-singinst_56-0
[520]: http://singinst.org/upload/artificial-intelligence-risk.pdf
[521]: #cite_ref-singinst9_57-0
[522]: http://www.singinst.org/blog/2007/06/11/the-stamp-collecting-device/
[523]: #cite_ref-aleph_58-0
[524]: http://www.aleph.se/andart/archives/2011/02/why_we_should_fear_the_paperclipper.html
[525]: #cite_ref-selfawaresystems10_59-0
[526]: #cite_ref-forbes_60-0
[527]: http://www.forbes.com/2009/06/18/cosmist-terran-cyborgist-opinions-contributors-artificial-intelligence-09-hugo-de-garis.html
[528]: #cite_ref-berglas_61-0
[529]: http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html#mozTocId817119
[530]: #cite_ref-philosophical_62-0
[531]: #cite_ref-singinst12_63-0
[532]: http://singinst.org/upload/CEV.html
[533]: #cite_ref-nytimes_july09_64-0
[534]: http://www.nytimes.com/2009/07/26/science/26robot.html?_r=1&ref=todayspaper
[535]: #cite_ref-palmer_65-0
[536]: http://news.bbc.co.uk/2/hi/technology/8182003.stm
[537]: #cite_ref-dailytech_66-0
[538]: http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm
[539]: #cite_ref-engadget_67-0
[540]: http://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/
[541]: #cite_ref-microsoft_68-0
[542]: http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm
[543]: #cite_ref-asimovlaws_69-0
[544]: http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html
[545]: #cite_ref-civilization_70-0
[546]: #cite_ref-dreyfus_71-0
[547]: #CITEREFDreyfusDreyfus2000
[548]: #CITEREFHawking1998
[549]: #cite_ref-thelightsinthetunnel_72-0
[550]: http://www.thelightsinthetunnel.com
[551]: http://en.wikipedia.org/wiki/Special:BookSources/9781448659814
[552]: #cite_ref-nytimes_73-0
[553]: http://www.nytimes.com/2011/03/05/science/05legal.html
[554]: #cite_ref-google13_74-0
[555]: http://www.google.com/search?q=cache:5qYje63ynXwJ:ourworld.compuserve.com/homepages/tmodis/TedWEB.htm+http://ourworld.compuserve.com/homepages/tmodis/TedWEB.htm&cd=1&hl=en&ct=clnk&gl=us
[556]: #cite_ref-Singularity_Myth_75-0
[557]: #cite_ref-Singularity_Myth_75-1
[558]: http://www.growth-dynamics.com/articles/Kurzweil.htm
[559]: #cite_ref-technological14_76-0
[560]: #cite_ref-technological14_76-1
[561]: #cite_ref-accelerating_77-0
[562]: http://accelerating.org/articles/huebnerinnovation.html
[563]: #cite_ref-cnet_78-0
[564]: http://news.cnet.com/2100-1006_3-6119618.html
[565]: #cite_ref-cliodynamics_79-0
[566]: http://cliodynamics.ru/index.php?option=com_content&task=view&id=124&Itemid=70
[567]: http://jwsr.ucr.edu/archive/vol11/number1/pdf/jwsr-v11n1-korotayev.pdf
[568]: #cite_ref-80
[569]: http://arxiv.org/abs/1206.0496
[570]: #cite_ref-interstellar_81-0
[571]: #cite_ref-university_82-0
[572]: #cite_ref-PZMyers_83-0
[573]: http://scienceblogs.com/pharyngula/2009/02/singularly_silly_singularity.php
[574]: #cite_ref-moreblades_84-0
[575]: http://www.economist.com/science/displaystory.cfm?story_id=5624861
[576]: #cite_ref-plugandpray-film_85-0
[577]: http://www.plugandpray-film.de/en/
[578]: #cite_ref-cnet15_86-0
[579]: http://news.cnet.com/robo-scientist-makes-gene-discovery-on-its-own/?tag=newsLatestHeadlinesArea.0
[580]: #cite_ref-wired_87-0
[581]: http://www.wired.com/wiredscience/2009/04/newtonai/
[582]: #cite_ref-cornell_88-0
[583]: http://www.news.cornell.edu/stories/April09/NaturalLaws.ws.html
[584]: #cite_ref-IEET_interview_89-0
[585]: http://ieet.org/index.php/IEET/more/2572/
[586]: #cite_ref-Paranoia_magazine_90-0
[587]: http://www.paranoiamagazine.com/backissues.html
[588]: #cite_ref-Paranoia_magazine_clipping_91-0
[589]: http://worlddominationtoys.com/drsteel/clippings_paranoia.html
[590]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=15
[591]: http://www.accelerating.org/about.html
[592]: http://en.wikipedia.org/wiki/James_John_Bell
[593]: http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/
[594]: http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm
[595]: http://en.wikipedia.org/wiki/World_Future_Society
[596]: http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html
[597]: http://en.wikipedia.org/wiki/Special:BookSources/0-312-87781-1
[598]: http://en.wikipedia.org/wiki/Journal_of_Evolution_and_Technology
[599]: http://en.wikipedia.org/wiki/Hubert_Dreyfus
[600]: http://en.wikipedia.org/wiki/Stuart_Dreyfus
[601]: http://en.wikipedia.org/wiki/Special:BookSources/0-7432-0551-0
[602]: http://en.wikipedia.org/wiki/Special:BookSources/978-1-4486-5981-4
[603]: http://web.archive.org/web/20010527181244/http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html
[604]: http://en.wikipedia.org/wiki/Academic_Press
[605]: http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html
[606]: http://hanson.gmu.edu/vc.html#hanson
[607]: http://en.wikipedia.org/wiki/Stephen_Hawking
[608]: http://clinton2.nara.gov/Initiatives/Millennium/shawking.html
[609]: http://en.wikipedia.org/wiki/Gerald_Hawkins
[610]: http://en.wikipedia.org/wiki/Special:BookSources/0-06-015156-0
[611]: http://en.wikipedia.org/wiki/Francis_Heylighen
[612]: http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf
[613]: http://en.wikipedia.org/wiki/George_Modelski
[614]: http://en.wikipedia.org/wiki/Special:BookSources/978-0-415-77361-4
[615]: http://hjem.get2net.dk/kgs/growthphysA.pdf
[616]: http://dx.doi.org/10.1016%2FS0378-4371%2801%2900105-4
[617]: http://en.wikipedia.org/wiki/Raymond_Kurzweil
[618]: http://lifeboat.com/ex/law.of.accelerating.returns
[619]: http://en.wikipedia.org/wiki/Special:BookSources/0-670-03384-7
[620]: http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html
[621]: http://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber
[622]: http://en.wikipedia.org/wiki/ArXiv
[623]: http://arxiv.org/abs/cs/0606081
[624]: http://arxiv.org/archive/cs.AI
[625]: http://web.archive.org/20061004201151/www.singinst.org/intro/whyAI-print.html
[626]: http://en.wikipedia.org/wiki/Wayback_Machine
[627]: http://www.asimovlaws.com/
[628]: http://www.singinst.org/overview/whatisthesingularity
[629]: http://en.wikipedia.org/wiki/Stanislaw_Ulam
[630]: http://mindstalk.net/vinge/vinge-sing.html
[631]: http://en.wikipedia.org/wiki/Kevin_Warwick
[632]: http://en.wikipedia.org/wiki/Special:BookSources/978-0-252-07223-9
[633]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=16
[634]: http://en.wikipedia.org/wiki/File:TechSingularity.ogg
[635]: //bits.wikimedia.org/static-1.20wmf5/extensions/OggHandler/play.png
[636]: //upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/45px-Sound-icon.svg.png
[637]: http://en.wikipedia.org/wiki/Wikipedia:Media_help
[638]: http://en.wikipedia.org/wiki/Wikipedia:Spoken_articles
[639]: //upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/15px-Sound-icon.svg.png
[640]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=17
[641]: http://lifeboat.com/ex/singularities.and.nightmares
[642]: http://hanson.gmu.edu/vi.html
[643]: http://hanson.gmu.edu/fastgrow.html
[644]: http://www.accelerationwatch.com/history_brief.html
[645]: http://www.edge.org/documents/archive/edge74.html
[646]: http://www.kurzweilai.net/meme/frame.html?main=/articles/art0236.html
[647]: http://fortnightlyreview.co.uk/2010/08/the-wonders-of-man-in-the-age-of-simulations/
[648]: http://www.kk.org/thetechnium/archives/2006/02/the_singularity.php
[649]: http://en.wikipedia.org/wiki/Kevin_Kelly_(editor)
[650]: http://www.kk.org/thetechnium/archives/2007/03/the_maesgarreau.php
[651]: http://en.wikipedia.org/wiki/David_Chalmers
[652]: http://www.time.com/time/health/article/0,8599,2048138,00.html
[653]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=18
[654]: http://www.singinst.org/
[655]: http://www.ssec.wisc.edu/~billh/g/mi.html
[656]: http://www.agiri.org/
[657]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=19
[658]: http://sifter.org/~simon/AfterLife/
[659]: http://www.ssec.wisc.edu/~billh/g/mcnrs.html
[660]: http://goertzel.org/fiction.htm
[661]: http://en.wikipedia.org/wiki/List_of_Terminator:_The_Sarah_Connor_Chronicles_minor_characters#John_Henry
[662]: http://en.wikipedia.org/wiki/Terminator:_The_Sarah_Connor_Chronicles
[663]: http://www.dresdencodak.com/cartoons/dc_032.htm
[664]: http://en.wikipedia.org/wiki/Endgame:_Singularity
[665]: http://en.wikipedia.org/wiki/Open_source
[666]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&action=edit&section=20
[667]: http://www.jerrypournelle.com/reports/jerryp/singularity.html
[668]: http://www.singinst.org/summit2007/quotes/
[669]: http://singularityhub.com
[670]: http://www.spectrum.ieee.org/static/singularity
[671]: http://www.house.gov/jec/publications/110/nanotechnology_03-22-07.pdf
[672]: http://www.thenewatlantis.com/docLib/20120213_TheFutureisComingSoonerThanYouThink.pdf
[673]: http://www.theglobaltransition.com
[674]: http://en.wikipedia.org/wiki/Template:Technology
[675]: http://en.wikipedia.org/wiki/Template_talk:Technology
[676]: //en.wikipedia.org/w/index.php?title=Template:Technology&action=edit
[677]: http://en.wikipedia.org/wiki/Technology
[678]: http://en.wikipedia.org/wiki/Outline_of_technology
[679]: http://en.wikipedia.org/wiki/Outline_of_applied_science
[680]: http://en.wikipedia.org/wiki/Agricultural_engineering
[681]: http://en.wikipedia.org/wiki/Aquaculture
[682]: http://en.wikipedia.org/wiki/Fisheries_science
[683]: http://en.wikipedia.org/wiki/Food_chemistry
[684]: http://en.wikipedia.org/wiki/Food_engineering
[685]: http://en.wikipedia.org/wiki/Food_microbiology
[686]: http://en.wikipedia.org/wiki/Food_technology
[687]: http://en.wikipedia.org/wiki/Genetic_use_restriction_technology
[688]: http://en.wikipedia.org/wiki/ICT_in_agriculture
[689]: http://en.wikipedia.org/wiki/Nutrition
[690]: http://en.wikipedia.org/wiki/Biomedical_technology
[691]: http://en.wikipedia.org/wiki/Bioinformatics
[692]: http://en.wikipedia.org/wiki/Biological_engineering
[693]: http://en.wikipedia.org/wiki/Biomechatronics
[694]: http://en.wikipedia.org/wiki/Biomedical_engineering
[695]: http://en.wikipedia.org/wiki/Biotechnology
[696]: http://en.wikipedia.org/wiki/Cheminformatics
[697]: http://en.wikipedia.org/wiki/Healthcare_science
[698]: http://en.wikipedia.org/wiki/Medical_research
[699]: http://en.wikipedia.org/wiki/Medical_technology
[700]: http://en.wikipedia.org/wiki/Nanomedicine
[701]: http://en.wikipedia.org/wiki/Neuroscience
[702]: http://en.wikipedia.org/wiki/Pharmacology
[703]: http://en.wikipedia.org/wiki/Reproductive_technology
[704]: http://en.wikipedia.org/wiki/Tissue_engineering
[705]: http://en.wikipedia.org/wiki/Acoustical_engineering
[706]: http://en.wikipedia.org/wiki/Architectural_engineering
[707]: http://en.wikipedia.org/wiki/Building_services_engineering
[708]: http://en.wikipedia.org/wiki/Civil_engineering
[709]: http://en.wikipedia.org/wiki/Construction_engineering
[710]: http://en.wikipedia.org/wiki/Domestic_technology
[711]: http://en.wikipedia.org/wiki/Facade_engineering
[712]: http://en.wikipedia.org/wiki/Fire_protection_engineering
[713]: http://en.wikipedia.org/wiki/Safety_engineering
[714]: http://en.wikipedia.org/wiki/Sanitary_engineering
[715]: http://en.wikipedia.org/wiki/Structural_engineering
[716]: http://en.wikipedia.org/wiki/Educational_technology
[717]: http://en.wikipedia.org/wiki/Educational_software
[718]: http://en.wikipedia.org/wiki/Digital_technologies_in_education
[719]: http://en.wikipedia.org/wiki/Information_and_communication_technologies_in_education
[720]: http://en.wikipedia.org/wiki/Impact_of_technology_on_the_educational_system
[721]: http://en.wikipedia.org/wiki/Multimedia_learning
[722]: http://en.wikipedia.org/wiki/Virtual_campus
[723]: http://en.wikipedia.org/wiki/Virtual_education
[724]: http://en.wikipedia.org/wiki/Energy_technology
[725]: http://en.wikipedia.org/wiki/Nuclear_engineering
[726]: http://en.wikipedia.org/wiki/Nuclear_technology
[727]: http://en.wikipedia.org/wiki/Petroleum_engineering
[728]: http://en.wikipedia.org/wiki/Soft_energy_technology
[729]: http://en.wikipedia.org/wiki/Environmental_technology
[730]: http://en.wikipedia.org/wiki/Clean_technology
[731]: http://en.wikipedia.org/wiki/Clean_coal_technology
[732]: http://en.wikipedia.org/wiki/Ecological_design
[733]: http://en.wikipedia.org/wiki/Ecological_engineering
[734]: http://en.wikipedia.org/wiki/Ecotechnology
[735]: http://en.wikipedia.org/wiki/Environmental_engineering
[736]: http://en.wikipedia.org/wiki/Environmental_engineering_science
[737]: http://en.wikipedia.org/wiki/Green_building
[738]: http://en.wikipedia.org/wiki/Green_nanotechnology
[739]: http://en.wikipedia.org/wiki/Landscape_engineering
[740]: http://en.wikipedia.org/wiki/Renewable_energy
[741]: http://en.wikipedia.org/wiki/Sustainable_design
[742]: http://en.wikipedia.org/wiki/Sustainable_engineering
[743]: http://en.wikipedia.org/wiki/Industrial_technology
[744]: http://en.wikipedia.org/wiki/Automation
[745]: http://en.wikipedia.org/wiki/Business_informatics
[746]: http://en.wikipedia.org/wiki/Engineering_management
[747]: http://en.wikipedia.org/wiki/Enterprise_engineering
[748]: http://en.wikipedia.org/wiki/Computational_finance
[749]: http://en.wikipedia.org/wiki/Industrial_biotechnology
[750]: http://en.wikipedia.org/wiki/Industrial_engineering
[751]: http://en.wikipedia.org/wiki/Metallurgy
[752]: http://en.wikipedia.org/wiki/Mining_engineering
[753]: http://en.wikipedia.org/wiki/Productivity_improving_technologies_(historical)
[754]: http://en.wikipedia.org/wiki/Research_and_development
[755]: http://en.wikipedia.org/wiki/Information_and_communications_technology
[756]: http://en.wikipedia.org/wiki/Broadcast_engineering
[757]: http://en.wikipedia.org/wiki/Computer_engineering
[758]: http://en.wikipedia.org/wiki/Computer_science
[759]: http://en.wikipedia.org/wiki/Information_technology
[760]: http://en.wikipedia.org/wiki/Music_technology
[761]: http://en.wikipedia.org/wiki/Ontology_engineering
[762]: http://en.wikipedia.org/wiki/RF_engineering
[763]: http://en.wikipedia.org/wiki/Software_engineering
[764]: http://en.wikipedia.org/wiki/Telecommunications_engineering
[765]: http://en.wikipedia.org/wiki/Visual_technology
[766]: http://en.wikipedia.org/wiki/Military_technology
[767]: http://en.wikipedia.org/wiki/Army_engineering_maintenance
[768]: http://en.wikipedia.org/wiki/Electronic_warfare
[769]: http://en.wikipedia.org/wiki/Military_communications
[770]: http://en.wikipedia.org/wiki/Military_engineering
[771]: http://en.wikipedia.org/wiki/Stealth_technology
[772]: http://en.wikipedia.org/wiki/Transport
[773]: http://en.wikipedia.org/wiki/Aerospace_engineering
[774]: http://en.wikipedia.org/wiki/Automotive_engineering
[775]: http://en.wikipedia.org/wiki/Naval_architecture
[776]: http://en.wikipedia.org/wiki/Space_technology
[777]: http://en.wikipedia.org/wiki/Traffic_engineering_(transportation)
[778]: http://en.wikipedia.org/wiki/Transport_engineering
[779]: http://en.wikipedia.org/wiki/Applied_science
[780]: http://en.wikipedia.org/wiki/Cryogenics
[781]: http://en.wikipedia.org/wiki/Electronics
[782]: http://en.wikipedia.org/wiki/Engineering_geology
[783]: http://en.wikipedia.org/wiki/Engineering_physics
[784]: http://en.wikipedia.org/wiki/Hydraulics
[785]: http://en.wikipedia.org/wiki/Materials_science
[786]: http://en.wikipedia.org/wiki/Microtechnology
[787]: http://en.wikipedia.org/wiki/Particle_physics
[788]: http://en.wikipedia.org/wiki/Engineering
[789]: http://en.wikipedia.org/wiki/Audio_engineering
[790]: http://en.wikipedia.org/wiki/Biochemical_engineering
[791]: http://en.wikipedia.org/wiki/Ceramic_engineering
[792]: http://en.wikipedia.org/wiki/Chemical_engineering
[793]: http://en.wikipedia.org/wiki/Control_engineering
[794]: http://en.wikipedia.org/wiki/Electrical_engineering
[795]: http://en.wikipedia.org/wiki/Electronic_engineering
[796]: http://en.wikipedia.org/wiki/Entertainment_engineering
[797]: http://en.wikipedia.org/wiki/Geotechnical_engineering
[798]: http://en.wikipedia.org/wiki/Hydraulic_engineering
[799]: http://en.wikipedia.org/wiki/Mechanical_engineering
[800]: http://en.wikipedia.org/wiki/Mechatronics
[801]: http://en.wikipedia.org/wiki/Optical_engineering
[802]: http://en.wikipedia.org/wiki/Protein_engineering
[803]: http://en.wikipedia.org/wiki/Quantum_technology
[804]: http://en.wikipedia.org/wiki/Robotics
[805]: http://en.wikipedia.org/wiki/Systems_engineering
[806]: http://en.wikipedia.org/wiki/History_of_technology
[807]: http://en.wikipedia.org/wiki/Outline_of_prehistoric_technology
[808]: http://en.wikipedia.org/wiki/Ancient_technology
[809]: http://en.wikipedia.org/wiki/Medieval_technology
[810]: http://en.wikipedia.org/wiki/Renaissance_technology
[811]: http://en.wikipedia.org/wiki/Second_Industrial_Revolution
[812]: http://en.wikipedia.org/wiki/Jet_Age
[813]: http://en.wikipedia.org/wiki/Information_Age
[814]: http://en.wikipedia.org/wiki/Theories_of_technology
[815]: http://en.wikipedia.org/wiki/Appropriate_technology
[816]: http://en.wikipedia.org/wiki/Critique_of_technology
[817]: http://en.wikipedia.org/wiki/Diffusion_of_innovations
[818]: http://en.wikipedia.org/wiki/Disruptive_technology
[819]: http://en.wikipedia.org/wiki/Ephemeralization
[820]: http://en.wikipedia.org/wiki/Ethics_of_technology
[821]: http://en.wikipedia.org/wiki/High_tech
[822]: http://en.wikipedia.org/wiki/Hype_cycle
[823]: http://en.wikipedia.org/wiki/Inevitability_thesis
[824]: http://en.wikipedia.org/wiki/Low-technology
[825]: http://en.wikipedia.org/wiki/Mature_technology
[826]: http://en.wikipedia.org/wiki/Philosophy_of_technology
[827]: http://en.wikipedia.org/wiki/Posthumanism
[828]: http://en.wikipedia.org/wiki/Strategy_of_Technology
[829]: http://en.wikipedia.org/wiki/Technicism
[830]: http://en.wikipedia.org/wiki/Techno-progressivism
[831]: http://en.wikipedia.org/wiki/Technocentrism
[832]: http://en.wikipedia.org/wiki/Technocracy
[833]: http://en.wikipedia.org/wiki/Technocriticism
[834]: http://en.wikipedia.org/wiki/Technological_change
[835]: http://en.wikipedia.org/wiki/Technological_convergence
[836]: http://en.wikipedia.org/wiki/Technological_escalation
[837]: http://en.wikipedia.org/wiki/Technological_innovation_system
[838]: http://en.wikipedia.org/wiki/Technological_momentum
[839]: http://en.wikipedia.org/wiki/Technological_nationalism
[840]: http://en.wikipedia.org/wiki/Technological_rationality
[841]: http://en.wikipedia.org/wiki/Technological_revival
[842]: http://en.wikipedia.org/wiki/Technological_somnambulism
[843]: http://en.wikipedia.org/wiki/Technological_utopianism
[844]: http://en.wikipedia.org/wiki/Technology_life_cycle
[845]: http://en.wikipedia.org/wiki/Technology_acceptance_model
[846]: http://en.wikipedia.org/wiki/Technology_adoption_lifecycle
[847]: http://en.wikipedia.org/wiki/Technorealism
[848]: http://en.wikipedia.org/wiki/Emerging_technologies
[849]: http://en.wikipedia.org/wiki/Fictional_technology
[850]: http://en.wikipedia.org/wiki/Category:High-technology_business_districts
[851]: http://en.wikipedia.org/wiki/Invention
[852]: http://en.wikipedia.org/wiki/Timeline_of_historic_inventions
[853]: http://en.wikipedia.org/wiki/List_of_technologies
[854]: http://en.wikipedia.org/wiki/Category:Science_and_technology_by_country
[855]: http://en.wikipedia.org/wiki/Technology_assessment
[856]: http://en.wikipedia.org/wiki/Technology_brokering
[857]: http://en.wikipedia.org/wiki/Category:Technology_companies
[858]: http://en.wikipedia.org/wiki/Technology_education
[859]: http://en.wikipedia.org/wiki/Category:Technical_universities_and_colleges
[860]: http://en.wikipedia.org/wiki/Technology_journalism
[861]: http://en.wikipedia.org/wiki/Technology_management
[862]: http://en.wikipedia.org/wiki/Technology_and_society
[863]: http://en.wikipedia.org/wiki/Technology_transfer
[864]: //upload.wikimedia.org/wikipedia/commons/thumb/8/89/Symbol_book_class2.svg/16px-Symbol_book_class2.svg.png
[865]: http://en.wikipedia.org/wiki/Book:Technology
[866]: //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png
[867]: http://en.wikipedia.org/wiki/Category:Technology
[868]: //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png
[869]: //commons.wikimedia.org/wiki/Category:Technology
[870]: //upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/16px-Portal-puzzle.svg.png
[871]: http://en.wikipedia.org/wiki/Portal:Technology
[872]: //upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/13px-Wikiquote-logo.svg.png
[873]: //en.wikiquote.org/wiki/Technology
[874]: http://en.wikipedia.org/wiki/Template:Emerging_technologies
[875]: http://en.wikipedia.org/wiki/Template_talk:Emerging_technologies
[876]: //en.wikipedia.org/w/index.php?title=Template:Emerging_technologies&action=edit
[877]: http://en.wikipedia.org/wiki/Agriculture
[878]: http://en.wikipedia.org/wiki/Agricultural_robot
[879]: http://en.wikipedia.org/wiki/In_vitro_meat
[880]: http://en.wikipedia.org/wiki/Genetically_modified_food
[881]: http://en.wikipedia.org/wiki/Precision_agriculture
[882]: http://en.wikipedia.org/wiki/Vertical_farming
[883]: http://en.wikipedia.org/wiki/Ampakine
[884]: http://en.wikipedia.org/wiki/Cryonics
[885]: http://en.wikipedia.org/wiki/Full_genome_sequencing
[886]: http://en.wikipedia.org/wiki/Gene_therapy
[887]: http://en.wikipedia.org/wiki/Personalized_medicine
[888]: http://en.wikipedia.org/wiki/Regenerative_medicine
[889]: http://en.wikipedia.org/wiki/Stem_cell_treatments
[890]: http://en.wikipedia.org/wiki/Robotic_surgery
[891]: http://en.wikipedia.org/wiki/Strategies_for_Engineered_Negligible_Senescence
[892]: http://en.wikipedia.org/wiki/Suspended_animation
[893]: http://en.wikipedia.org/wiki/Synthetic_biology
[894]: http://en.wikipedia.org/wiki/Synthetic_genomics
[895]: http://en.wikipedia.org/wiki/Whole-body_transplant
[896]: http://en.wikipedia.org/wiki/Head_transplant
[897]: http://en.wikipedia.org/wiki/Isolated_brain
[898]: http://en.wikipedia.org/wiki/Autostereoscopy
[899]: http://en.wikipedia.org/wiki/Holographic_display
[900]: http://en.wikipedia.org/wiki/Next_generation_of_display_technology
[901]: http://en.wikipedia.org/wiki/Screenless
[902]: http://en.wikipedia.org/wiki/Bionic_contact_lens
[903]: http://en.wikipedia.org/wiki/Head-mounted_display
[904]: http://en.wikipedia.org/wiki/Head-up_display
[905]: http://en.wikipedia.org/wiki/Virtual_retinal_display
[906]: http://en.wikipedia.org/wiki/Ultra_High_Definition_Television
[907]: http://en.wikipedia.org/wiki/Electronic_nose
[908]: http://en.wikipedia.org/wiki/Electronic_textile
[909]: http://en.wikipedia.org/wiki/Flexible_electronics
[910]: http://en.wikipedia.org/wiki/Memristor
[911]: http://en.wikipedia.org/wiki/Spintronics
[912]: http://en.wikipedia.org/wiki/Thermal_copper_pillar_bump
[913]: http://en.wikipedia.org/wiki/Energy_storage
[914]: http://en.wikipedia.org/wiki/Beltway_battery
[915]: http://en.wikipedia.org/wiki/Compressed_air_energy_storage
[916]: http://en.wikipedia.org/wiki/Flywheel_energy_storage
[917]: http://en.wikipedia.org/wiki/Grid_energy_storage
[918]: http://en.wikipedia.org/wiki/Lithium_air_battery
[919]: http://en.wikipedia.org/wiki/Molten_salt_battery
[920]: http://en.wikipedia.org/wiki/Nanowire_battery
[921]: http://en.wikipedia.org/wiki/Silicon_air_battery
[922]: http://en.wikipedia.org/wiki/Thermal_energy_storage
[923]: http://en.wikipedia.org/wiki/Electric_double-layer_capacitor
[924]: http://en.wikipedia.org/wiki/Fusion_power
[925]: http://en.wikipedia.org/wiki/Molten_salt_reactor
[926]: http://en.wikipedia.org/wiki/Airborne_wind_turbine
[927]: http://en.wikipedia.org/wiki/Artificial_photosynthesis
[928]: http://en.wikipedia.org/wiki/Biofuel
[929]: http://en.wikipedia.org/wiki/Concentrated_solar_power
[930]: http://en.wikipedia.org/wiki/Home_fuel_cell
[931]: http://en.wikipedia.org/wiki/Hydrogen_economy
[932]: http://en.wikipedia.org/wiki/Nantenna
[933]: http://en.wikipedia.org/wiki/Solar_roadway
[934]: http://en.wikipedia.org/wiki/Space-based_solar_power
[935]: http://en.wikipedia.org/wiki/Smart_grid
[936]: http://en.wikipedia.org/wiki/Wireless_energy_transfer
[937]: http://en.wikipedia.org/wiki/Information_and_communication_technologies
[938]: http://en.wikipedia.org/wiki/Applications_of_artificial_intelligence
[939]: http://en.wikipedia.org/wiki/Progress_in_artificial_intelligence
[940]: http://en.wikipedia.org/wiki/Machine_translation
[941]: http://en.wikipedia.org/wiki/Machine_vision
[942]: http://en.wikipedia.org/wiki/Semantic_Web
[943]: http://en.wikipedia.org/wiki/Atomtronics
[944]: http://en.wikipedia.org/wiki/Cybermethodology
[945]: http://en.wikipedia.org/wiki/Optical_disc#Fourth-generation
[946]: http://en.wikipedia.org/wiki/3D_optical_data_storage
[947]: http://en.wikipedia.org/wiki/Holographic_data_storage
[948]: http://en.wikipedia.org/wiki/GPGPU
[949]: http://en.wikipedia.org/wiki/CBRAM
[950]: http://en.wikipedia.org/wiki/Ferroelectric_RAM
[951]: http://en.wikipedia.org/wiki/Millipede_memory
[952]: http://en.wikipedia.org/wiki/Magnetoresistive_random-access_memory
[953]: http://en.wikipedia.org/wiki/Nano-RAM
[954]: http://en.wikipedia.org/wiki/Phase-change_memory
[955]: http://en.wikipedia.org/wiki/Racetrack_memory
[956]: http://en.wikipedia.org/wiki/RRAM
[957]: http://en.wikipedia.org/wiki/SONOS
[958]: http://en.wikipedia.org/wiki/Optical_computing
[959]: http://en.wikipedia.org/wiki/Quantum_computer
[960]: http://en.wikipedia.org/wiki/Quantum_cryptography
[961]: http://en.wikipedia.org/wiki/Radio-frequency_identification
[962]: http://en.wikipedia.org/wiki/Three-dimensional_integrated_circuit
[963]: http://en.wikipedia.org/wiki/3D_printing
[964]: http://en.wikipedia.org/wiki/Contour_Crafting
[965]: http://en.wikipedia.org/wiki/Claytronics
[966]: http://en.wikipedia.org/wiki/Molecular_assembler
[967]: http://en.wikipedia.org/wiki/Utility_fog
[968]: http://en.wikipedia.org/wiki/Graphene
[969]: http://en.wikipedia.org/wiki/High-temperature_superconductivity
[970]: http://en.wikipedia.org/wiki/Superfluid
[971]: http://en.wikipedia.org/wiki/Metamaterial
[972]: http://en.wikipedia.org/wiki/Metamaterial_cloaking
[973]: http://en.wikipedia.org/wiki/Multi-function_structure
[974]: http://en.wikipedia.org/wiki/Carbon_nanotube
[975]: http://en.wikipedia.org/wiki/Nanomaterials
[976]: http://en.wikipedia.org/wiki/Programmable_matter
[977]: http://en.wikipedia.org/wiki/Quantum_dot
[978]: http://en.wikipedia.org/wiki/Antimatter_weapon
[979]: http://en.wikipedia.org/wiki/Directed-energy_weapon
[980]: http://en.wikipedia.org/wiki/Laser
[981]: http://en.wikipedia.org/wiki/Maser
[982]: http://en.wikipedia.org/wiki/Particle_beam_weapon
[983]: http://en.wikipedia.org/wiki/Sonic_weapon
[984]: http://en.wikipedia.org/wiki/Electromagnetic_weapon
[985]: http://en.wikipedia.org/wiki/Coilgun
[986]: http://en.wikipedia.org/wiki/Railgun
[987]: http://en.wikipedia.org/wiki/Plasma_weapon
[988]: http://en.wikipedia.org/wiki/Pure_fusion_weapon
[989]: http://en.wikipedia.org/wiki/Artificial_brain
[990]: http://en.wikipedia.org/wiki/Blue_Brain_Project
[991]: http://en.wikipedia.org/wiki/Electroencephalography
[992]: http://en.wikipedia.org/wiki/Brain-reading
[993]: http://en.wikipedia.org/wiki/Neuroinformatics
[994]: http://en.wikipedia.org/wiki/Neuroprosthetics
[995]: http://en.wikipedia.org/wiki/Visual_prosthesis
[996]: http://en.wikipedia.org/wiki/Brain_implant
[997]: http://en.wikipedia.org/wiki/Exocortex
[998]: http://en.wikipedia.org/wiki/Retinal_implant
[999]: http://en.wikipedia.org/wiki/Nanorobotics
[1000]: http://en.wikipedia.org/wiki/Powered_exoskeleton
[1001]: http://en.wikipedia.org/wiki/Self-reconfiguring_modular_robot
[1002]: http://en.wikipedia.org/wiki/Swarm_robotics
[1003]: http://en.wikipedia.org/wiki/Adaptive_Compliant_Wing
[1004]: http://en.wikipedia.org/wiki/Alternative_fuel_vehicle
[1005]: http://en.wikipedia.org/wiki/Hydrogen_vehicle
[1006]: http://en.wikipedia.org/wiki/Backpack_helicopter
[1007]: http://en.wikipedia.org/wiki/Autonomous_car
[1008]: http://en.wikipedia.org/wiki/Flying_car_(aircraft)
[1009]: http://en.wikipedia.org/wiki/Ground_effect_train
[1010]: http://en.wikipedia.org/wiki/Jet_pack
[1011]: http://en.wikipedia.org/wiki/Interstellar_travel
[1012]: http://en.wikipedia.org/wiki/Laser_propulsion
[1013]: http://en.wikipedia.org/wiki/Maglev
[1014]: http://en.wikipedia.org/wiki/Non-rocket_spacelaunch
[1015]: http://en.wikipedia.org/wiki/Mass_driver
[1016]: http://en.wikipedia.org/wiki/Orbital_ring
[1017]: http://en.wikipedia.org/wiki/Skyhook_(structure)
[1018]: http://en.wikipedia.org/wiki/Space_elevator
[1019]: http://en.wikipedia.org/wiki/Space_fountain
[1020]: http://en.wikipedia.org/wiki/Space_tether
[1021]: http://en.wikipedia.org/wiki/Personal_rapid_transit
[1022]: http://en.wikipedia.org/wiki/Evacuated_Tube_Transport
[1023]: http://en.wikipedia.org/wiki/Pulse_detonation_engine
[1024]: http://en.wikipedia.org/wiki/Nuclear_pulse_propulsion
[1025]: http://en.wikipedia.org/wiki/Scramjet
[1026]: http://en.wikipedia.org/wiki/Solar_sail
[1027]: http://en.wikipedia.org/wiki/Spaceplane
[1028]: http://en.wikipedia.org/wiki/Supersonic_transport
[1029]: http://en.wikipedia.org/wiki/Tweel
[1030]: http://en.wikipedia.org/wiki/Vactrain
[1031]: http://en.wikipedia.org/wiki/Anti-gravity
[1032]: http://en.wikipedia.org/wiki/Arcology
[1033]: http://en.wikipedia.org/wiki/Cloak_of_invisibility
[1034]: http://en.wikipedia.org/wiki/Digital_scent_technology
[1035]: http://en.wikipedia.org/wiki/Domed_city
[1036]: http://en.wikipedia.org/wiki/Force_shield
[1037]: http://en.wikipedia.org/wiki/Plasma_window
[1038]: http://en.wikipedia.org/wiki/Immersion_(virtual_reality)
[1039]: http://en.wikipedia.org/wiki/Magnetic_refrigeration
[1040]: http://en.wikipedia.org/wiki/Phased-array_optics
[1041]: http://en.wikipedia.org/wiki/Quantum_teleportation
[1042]: http://en.wikipedia.org/wiki/Differential_technological_development
[1043]: http://en.wikipedia.org/wiki/Exploratory_engineering
[1044]: http://en.wikipedia.org/wiki/Technology_forecasting
[1045]: http://en.wikipedia.org/wiki/Timeline_of_the_future_in_forecasts
[1046]: http://en.wikipedia.org/wiki/Technology_scouting
[1047]: http://en.wikipedia.org/wiki/Technology_readiness_level
[1048]: http://en.wikipedia.org/wiki/Technology_roadmap
[1049]: http://en.wikipedia.org/wiki/Virtusphere
[1050]: http://en.wikipedia.org/wiki/Category:Emerging_technologies
[1051]: //upload.wikimedia.org/wikipedia/en/thumb/d/db/Symbol_list_class.svg/16px-Symbol_list_class.svg.png
[1052]: http://en.wikipedia.org/w/index.php?title=Technological_singularity&oldid=499252190
[1053]: http://en.wikipedia.org/wiki/Special:Categories
[1054]: http://en.wikipedia.org/wiki/Category:Evolution
[1055]: http://en.wikipedia.org/wiki/Category:Sociocultural_evolution
[1056]: http://en.wikipedia.org/wiki/Category:Theories_of_history
[1057]: http://en.wikipedia.org/wiki/Category:Futurology
[1058]: http://en.wikipedia.org/wiki/Category:Singularitarianism
[1059]: http://en.wikipedia.org/wiki/Category:Philosophy_of_artificial_intelligence
[1060]: http://en.wikipedia.org/wiki/Category:Eschatology
[1061]: http://en.wikipedia.org/wiki/Category:All_articles_with_dead_external_links
[1062]: http://en.wikipedia.org/wiki/Category:Articles_with_dead_external_links_from_July_2011
[1063]: http://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements
[1064]: http://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_October_2011
[1065]: http://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_August_2010
[1066]: http://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_October_2009
[1067]: http://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_November_2010
[1068]: http://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_March_2010
[1069]: http://en.wikipedia.org/wiki/Category:Articles_with_dead_external_links_from_July_2009
[1070]: http://en.wikipedia.org/wiki/Category:Wikipedia_external_links_cleanup_from_March_2011
[1071]: http://en.wikipedia.org/wiki/Category:Wikipedia_spam_cleanup_from_March_2011
[1072]: http://en.wikipedia.org/wiki/Category:Spoken_articles
[1073]: http://en.wikipedia.org/wiki/Category:Articles_with_hAudio_microformats
[1074]: http://en.wikipedia.org/wiki/Technological_singularity
[1075]: //creativecommons.org/licenses/by-sa/3.0/